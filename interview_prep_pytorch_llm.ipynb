{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e0bb95d",
   "metadata": {},
   "source": [
    "# ML, PyTorch & LLM Interview Preparation Guide\n",
    "\n",
    "A comprehensive guide covering Machine Learning fundamentals, PyTorch, and Large Language Model concepts for technical interviews.\n",
    "\n",
    "---\n",
    "\n",
    "##  Study Guide\n",
    "\n",
    "This guide is organized in optimal learning order. Each section builds on previous concepts.\n",
    "\n",
    "### Learning Path Overview\n",
    "\n",
    "| Part | Topic | Category |\n",
    "|------|-------|----------|\n",
    "| 1 | Machine Learning Fundamentals | Foundation |\n",
    "| 2 | Deep Learning Fundamentals | Foundation |\n",
    "| 3 | PyTorch Fundamentals | Foundation |\n",
    "| 4 | Convolutional Neural Networks (CNNs) | Core Architecture |\n",
    "| 5 | LLM & Transformer Concepts | Core Architecture |\n",
    "| 6 | Generative Models | Specialized |\n",
    "| 7 | Graph Neural Networks (GNNs) | Specialized |\n",
    "| 8 | Natural Language Processing Basics | Specialized |\n",
    "| 9 | Reinforcement Learning Fundamentals | Specialized |\n",
    "| 10 | Model Deployment & MLOps | Production |\n",
    "| 11 | Distributed Training | Production |\n",
    "| 12 | Debugging ML Models | Production |\n",
    "| 13 | ML System Design | Production |\n",
    "| 14 | Robotics & Embodied AI Fundamentals | Domain-Specific |\n",
    "| 15 | Data Augmentation | Techniques |\n",
    "| 16 | Ethics & Fairness in ML | Techniques |\n",
    "| 17 | Common Interview Questions | Review |\n",
    "| 18 | Code Snippets to Know | Review |\n",
    "| 19 | Quick Reference - Key Formulas | Reference |\n",
    "| 20 | Additional Interview Tips | Review |\n",
    "\n",
    "### Quick Navigation by Role\n",
    "\n",
    "- **ML Engineer (General):** Parts 1-3  4-5  10-13\n",
    "- **NLP/LLM Engineer:** Parts 1-3  5  8  10-11\n",
    "- **Computer Vision Engineer:** Parts 1-3  4  6  15  10\n",
    "- **Robotics/Embodied AI:** Parts 1-3  9  14  4\n",
    "- **Research Scientist:** Parts 1-3  5  6  9  7\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1: Machine Learning Fundamentals\n",
    "\n",
    "### 1.1 Types of Machine Learning\n",
    "\n",
    "**Supervised Learning**\n",
    "- Learn from labeled data (input → output pairs)\n",
    "- Examples: Classification, Regression\n",
    "- Algorithms: Linear Regression, Logistic Regression, SVM, Decision Trees, Neural Networks\n",
    "\n",
    "**Unsupervised Learning**\n",
    "- Learn patterns from unlabeled data\n",
    "- Examples: Clustering, Dimensionality Reduction, Anomaly Detection\n",
    "- Algorithms: K-Means, PCA, Autoencoders\n",
    "\n",
    "**Reinforcement Learning**\n",
    "- Learn through interaction with environment (actions → rewards)\n",
    "- Examples: Game playing, Robotics\n",
    "- Algorithms: Q-Learning, Policy Gradient, PPO\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 Bias-Variance Tradeoff\n",
    "\n",
    "**Q: Explain bias and variance**\n",
    "\n",
    "- **Bias:** Error from oversimplified assumptions. High bias = underfitting\n",
    "- **Variance:** Error from sensitivity to training data fluctuations. High variance = overfitting\n",
    "\n",
    "| | Low Variance | High Variance |\n",
    "|---|---|---|\n",
    "| **Low Bias** | Ideal (good fit) | Overfitting |\n",
    "| **High Bias** | Underfitting | Worst case |\n",
    "\n",
    "**Total Error = Bias² + Variance + Irreducible Error**\n",
    "\n",
    "**Q: How to reduce overfitting?**\n",
    "- More training data\n",
    "- Regularization (L1, L2, Dropout)\n",
    "- Simpler model\n",
    "- Early stopping\n",
    "- Cross-validation\n",
    "- Data augmentation\n",
    "\n",
    "**Q: How to reduce underfitting?**\n",
    "- More complex model\n",
    "- More features\n",
    "- Less regularization\n",
    "- Train longer\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3 Train/Validation/Test Split\n",
    "\n",
    "**Q: Why split data?**\n",
    "\n",
    "- **Training set (60-80%):** Learn model parameters\n",
    "- **Validation set (10-20%):** Tune hyperparameters, model selection\n",
    "- **Test set (10-20%):** Final unbiased evaluation\n",
    "\n",
    "**Q: What is cross-validation?**\n",
    "\n",
    "K-Fold CV: Split data into K folds, train on K-1, validate on 1, rotate K times.\n",
    "- More reliable estimate of model performance\n",
    "- Uses all data for both training and validation\n",
    "- Common: 5-fold or 10-fold\n",
    "\n",
    "**Code - Cross-Validation:**\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "# Simple train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y  # stratify for classification\n",
    ")\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
    "print(f\"CV Accuracy: {scores.mean():.3f} (+/- {scores.std()*2:.3f})\")\n",
    "\n",
    "# Manual K-Fold loop\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_val, y_val)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1.4 Evaluation Metrics\n",
    "\n",
    "**Classification Metrics:**\n",
    "\n",
    "| Metric | Formula | Use When |\n",
    "|--------|---------|----------|\n",
    "| Accuracy | (TP+TN)/(TP+TN+FP+FN) | Balanced classes |\n",
    "| Precision | TP/(TP+FP) | Cost of FP is high |\n",
    "| Recall | TP/(TP+FN) | Cost of FN is high |\n",
    "| F1 Score | 2×(P×R)/(P+R) | Imbalanced classes |\n",
    "| AUC-ROC | Area under ROC curve | Ranking quality |\n",
    "\n",
    "**Confusion Matrix:**\n",
    "```\n",
    "              Predicted\n",
    "              Pos    Neg\n",
    "Actual Pos    TP     FN\n",
    "       Neg    FP     TN\n",
    "```\n",
    "\n",
    "**Regression Metrics:**\n",
    "\n",
    "| Metric | Formula | Notes |\n",
    "|--------|---------|-------|\n",
    "| MSE | (1/n)Σ(y-ŷ)² | Penalizes large errors |\n",
    "| RMSE | √MSE | Same units as target |\n",
    "| MAE | (1/n)Σ\\|y-ŷ\\| | Robust to outliers |\n",
    "| R² | 1 - SS_res/SS_tot | % variance explained |\n",
    "\n",
    "**Code - Computing Metrics:**\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Classification\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Regression\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1.5 Feature Engineering\n",
    "\n",
    "**Q: What is feature scaling and why is it important?**\n",
    "\n",
    "- **Standardization (Z-score):** x' = (x - μ) / σ → mean=0, std=1\n",
    "- **Normalization (Min-Max):** x' = (x - min) / (max - min) → range [0,1]\n",
    "\n",
    "Important for:\n",
    "- Gradient-based optimization (faster convergence)\n",
    "- Distance-based algorithms (KNN, SVM, K-Means)\n",
    "- Regularization (fair penalty across features)\n",
    "\n",
    "**Code - Feature Scaling:**\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Standardization (Z-score normalization)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # fit on train only!\n",
    "X_test_scaled = scaler.transform(X_test)        # transform test\n",
    "\n",
    "# Min-Max Normalization\n",
    "minmax = MinMaxScaler()\n",
    "X_normalized = minmax.fit_transform(X_train)\n",
    "\n",
    "# Manual implementation\n",
    "mean, std = X_train.mean(axis=0), X_train.std(axis=0)\n",
    "X_standardized = (X_train - mean) / std\n",
    "```\n",
    "\n",
    "**Q: How to handle missing values?**\n",
    "- Remove rows/columns (if few missing)\n",
    "- Imputation: mean, median, mode\n",
    "- Model-based imputation\n",
    "- Create \"is_missing\" indicator feature\n",
    "\n",
    "**Q: How to handle categorical variables?**\n",
    "- One-hot encoding (nominal categories)\n",
    "- Label encoding (ordinal categories)\n",
    "- Target encoding (high cardinality)\n",
    "- Embeddings (for neural networks)\n",
    "\n",
    "**Code - Handling Categorical Variables:**\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# One-Hot Encoding (pandas)\n",
    "df_encoded = pd.get_dummies(df, columns=['category_col'], drop_first=True)\n",
    "\n",
    "# One-Hot Encoding (sklearn)\n",
    "onehot = OneHotEncoder(sparse=False, drop='first')\n",
    "encoded = onehot.fit_transform(df[['category_col']])\n",
    "\n",
    "# Label Encoding (for ordinal categories)\n",
    "le = LabelEncoder()\n",
    "df['category_encoded'] = le.fit_transform(df['category_col'])\n",
    "\n",
    "# PyTorch Embedding (for neural networks)\n",
    "num_categories = df['category_col'].nunique()\n",
    "embedding = nn.Embedding(num_categories, embedding_dim=8)\n",
    "embedded = embedding(torch.LongTensor(category_indices))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1.6 Regularization\n",
    "\n",
    "**Q: Explain L1 vs L2 regularization**\n",
    "\n",
    "| | L1 (Lasso) | L2 (Ridge) |\n",
    "|---|---|---|\n",
    "| Penalty | λΣ\\|w\\| | λΣw² |\n",
    "| Effect | Sparse weights (feature selection) | Small weights |\n",
    "| Solution | Not differentiable at 0 | Closed-form solution |\n",
    "\n",
    "**Elastic Net:** Combines L1 + L2\n",
    "\n",
    "**Code - Regularization:**\n",
    "```python\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "# L2 Regularization (Ridge)\n",
    "ridge = Ridge(alpha=1.0)  # alpha = regularization strength\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# L1 Regularization (Lasso)\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "print(f\"Non-zero coefficients: {(lasso.coef_ != 0).sum()}\")  # sparse!\n",
    "\n",
    "# Elastic Net (L1 + L2)\n",
    "elastic = ElasticNet(alpha=0.1, l1_ratio=0.5)  # l1_ratio: mix of L1/L2\n",
    "elastic.fit(X_train, y_train)\n",
    "\n",
    "# PyTorch weight decay (L2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# PyTorch Dropout\n",
    "dropout = nn.Dropout(p=0.5)  # 50% dropout rate\n",
    "```\n",
    "\n",
    "**Q: What is dropout?**\n",
    "\n",
    "Randomly set neurons to 0 during training with probability p. Forces network to not rely on any single neuron. Ensemble effect.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.7 Classical ML Algorithms\n",
    "\n",
    "**Linear Regression**\n",
    "- Predicts continuous output: ŷ = wᵀx + b\n",
    "- Loss: MSE\n",
    "- Closed-form solution or gradient descent\n",
    "\n",
    "**Logistic Regression**\n",
    "- Binary classification: P(y=1) = σ(wᵀx + b)\n",
    "- Loss: Binary Cross-Entropy\n",
    "- Despite name, it's classification!\n",
    "\n",
    "**Decision Trees**\n",
    "- Split data based on feature thresholds\n",
    "- Greedy algorithm (information gain, Gini impurity)\n",
    "- Prone to overfitting → use Random Forest\n",
    "\n",
    "**Random Forest**\n",
    "- Ensemble of decision trees\n",
    "- Bagging + random feature subsets\n",
    "- Reduces variance, more robust\n",
    "\n",
    "**Gradient Boosting (XGBoost, LightGBM)**\n",
    "- Sequential ensemble: each tree corrects previous errors\n",
    "- Often best for tabular data\n",
    "- Hyperparameters: learning rate, max depth, n_estimators\n",
    "\n",
    "**SVM (Support Vector Machine)**\n",
    "- Find hyperplane maximizing margin\n",
    "- Kernel trick for non-linear boundaries\n",
    "- Works well in high dimensions\n",
    "\n",
    "**K-Nearest Neighbors (KNN)**\n",
    "- Classify based on k nearest training points\n",
    "- No training phase (lazy learning)\n",
    "- Sensitive to feature scaling and curse of dimensionality\n",
    "\n",
    "**K-Means Clustering**\n",
    "- Partition data into k clusters\n",
    "- Iterative: assign points → update centroids\n",
    "- Choose k with elbow method or silhouette score\n",
    "\n",
    "**PCA (Principal Component Analysis)**\n",
    "- Dimensionality reduction\n",
    "- Find directions of maximum variance\n",
    "- Linear transformation, preserves global structure\n",
    "\n",
    "**Code - Classical ML Algorithms:**\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "probs = log_reg.predict_proba(X_test)\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# SVM\n",
    "svm = SVC(kernel='rbf', C=1.0)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# K-Means Clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "print(f\"Explained variance: {pca.explained_variance_ratio_}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1.8 Ensemble Methods\n",
    "\n",
    "**Q: Explain bagging vs boosting**\n",
    "\n",
    "| | Bagging | Boosting |\n",
    "|---|---|---|\n",
    "| Training | Parallel | Sequential |\n",
    "| Sampling | Bootstrap (with replacement) | Weighted samples |\n",
    "| Goal | Reduce variance | Reduce bias |\n",
    "| Example | Random Forest | XGBoost, AdaBoost |\n",
    "\n",
    "**Q: What is stacking?**\n",
    "\n",
    "Train multiple models, use their predictions as features for a meta-model.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.9 Hyperparameter Tuning\n",
    "\n",
    "**Methods:**\n",
    "- Grid Search: Try all combinations (exhaustive)\n",
    "- Random Search: Sample randomly (often better)\n",
    "- Bayesian Optimization: Model the objective function\n",
    "- Early Stopping: Stop when validation loss increases\n",
    "\n",
    "**Common hyperparameters:**\n",
    "- Learning rate\n",
    "- Regularization strength\n",
    "- Number of layers/neurons\n",
    "- Batch size\n",
    "- Number of trees/depth (for tree models)\n",
    "\n",
    "---\n",
    "\n",
    "### 1.10 Probability & Statistics Fundamentals\n",
    "\n",
    "**Q: What is Bayes' Theorem and why is it important?**\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$\n",
    "\n",
    "- **P(A|B):** Posterior - probability of A given B\n",
    "- **P(B|A):** Likelihood - probability of B given A\n",
    "- **P(A):** Prior - initial belief about A\n",
    "- **P(B):** Evidence - normalizing constant\n",
    "\n",
    "**Applications:** Naive Bayes classifier, Bayesian inference, spam filtering, medical diagnosis\n",
    "\n",
    "**Q: Explain common probability distributions**\n",
    "\n",
    "| Distribution | Type | Use Case | Parameters |\n",
    "|--------------|------|----------|------------|\n",
    "| Bernoulli | Discrete | Single binary outcome | p (success prob) |\n",
    "| Binomial | Discrete | n binary trials | n, p |\n",
    "| Poisson | Discrete | Count of rare events | λ (rate) |\n",
    "| Uniform | Continuous | Equal probability | a, b (bounds) |\n",
    "| Gaussian/Normal | Continuous | Natural phenomena | μ, σ |\n",
    "| Exponential | Continuous | Time between events | λ (rate) |\n",
    "\n",
    "**Key Formulas:**\n",
    "\n",
    "- **Gaussian PDF:** $p(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$\n",
    "- **Binomial:** $P(X=k) = \\binom{n}{k}p^k(1-p)^{n-k}$\n",
    "- **Poisson:** $P(X=k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}$\n",
    "\n",
    "**Q: Define key statistical concepts**\n",
    "\n",
    "| Concept | Formula | Meaning |\n",
    "|---------|---------|---------|\n",
    "| Expected Value | $\\mathbb{E}[X] = \\sum x_i P(x_i)$ | Average outcome |\n",
    "| Variance | $\\text{Var}(X) = \\mathbb{E}[(X-\\mu)^2]$ | Spread of data |\n",
    "| Std Deviation | $\\sigma = \\sqrt{\\text{Var}(X)}$ | Spread in original units |\n",
    "| Covariance | $\\text{Cov}(X,Y) = \\mathbb{E}[(X-\\mu_X)(Y-\\mu_Y)]$ | Joint variability |\n",
    "| Correlation | $\\rho = \\frac{\\text{Cov}(X,Y)}{\\sigma_X \\sigma_Y}$ | Normalized covariance [-1,1] |\n",
    "\n",
    "**Q: What is the Central Limit Theorem?**\n",
    "\n",
    "The sampling distribution of the mean approaches a normal distribution as sample size increases, regardless of the population distribution.\n",
    "\n",
    "- Enables hypothesis testing\n",
    "- Justifies using normal distribution in many ML algorithms\n",
    "- Rule of thumb: n ≥ 30 for CLT to apply\n",
    "\n",
    "**Q: Explain Maximum Likelihood Estimation (MLE)**\n",
    "\n",
    "Find parameters θ that maximize the probability of observing the data:\n",
    "\n",
    "$$\\hat{\\theta}_{MLE} = \\arg\\max_\\theta P(D|\\theta) = \\arg\\max_\\theta \\prod_i P(x_i|\\theta)$$\n",
    "\n",
    "In practice, maximize log-likelihood (easier to compute):\n",
    "$$\\hat{\\theta}_{MLE} = \\arg\\max_\\theta \\sum_i \\log P(x_i|\\theta)$$\n",
    "\n",
    "**Q: MLE vs MAP (Maximum A Posteriori)?**\n",
    "\n",
    "| | MLE | MAP |\n",
    "|---|---|---|\n",
    "| Formula | $\\arg\\max P(D\\|\\theta)$ | $\\arg\\max P(\\theta\\|D)$ |\n",
    "| Prior | No prior | Includes prior P(θ) |\n",
    "| Regularization | None | Prior acts as regularizer |\n",
    "| Overfitting | More prone | Less prone |\n",
    "\n",
    "MAP with Gaussian prior = L2 regularization\n",
    "\n",
    "**Q: What is hypothesis testing?**\n",
    "\n",
    "1. **Null Hypothesis (H₀):** Default assumption (no effect)\n",
    "2. **Alternative Hypothesis (H₁):** What we want to prove\n",
    "3. **p-value:** Probability of observing data if H₀ is true\n",
    "4. **Significance level (α):** Threshold (typically 0.05)\n",
    "5. **Decision:** Reject H₀ if p-value < α\n",
    "\n",
    "**Type I Error (False Positive):** Reject H₀ when it's true\n",
    "**Type II Error (False Negative):** Fail to reject H₀ when it's false\n",
    "\n",
    "**Q: What is the difference between population and sample statistics?**\n",
    "\n",
    "| Population | Sample |\n",
    "|------------|--------|\n",
    "| μ (mean) | x̄ (sample mean) |\n",
    "| σ² (variance) | s² (sample variance, divide by n-1) |\n",
    "| N (size) | n (sample size) |\n",
    "\n",
    "Bessel's correction (n-1) gives unbiased estimate of population variance.\n",
    "\n",
    "**Code - Probability & Statistics:**\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sampling from distributions\n",
    "normal_samples = np.random.normal(loc=0, scale=1, size=1000)  # μ=0, σ=1\n",
    "uniform_samples = np.random.uniform(low=0, high=1, size=1000)\n",
    "binomial_samples = np.random.binomial(n=10, p=0.5, size=1000)\n",
    "poisson_samples = np.random.poisson(lam=5, size=1000)\n",
    "\n",
    "# Descriptive statistics\n",
    "mean = np.mean(data)\n",
    "variance = np.var(data, ddof=1)  # ddof=1 for sample variance\n",
    "std = np.std(data, ddof=1)\n",
    "median = np.median(data)\n",
    "\n",
    "# Correlation and covariance\n",
    "correlation = np.corrcoef(x, y)[0, 1]\n",
    "covariance = np.cov(x, y)[0, 1]\n",
    "\n",
    "# Hypothesis testing - t-test\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2)  # independent samples\n",
    "t_stat, p_value = stats.ttest_rel(before, after)   # paired samples\n",
    "\n",
    "# Chi-square test (categorical data)\n",
    "chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "# Normality test\n",
    "stat, p_value = stats.shapiro(data)  # Shapiro-Wilk test\n",
    "\n",
    "# Confidence interval for mean\n",
    "confidence = 0.95\n",
    "sem = stats.sem(data)  # standard error of mean\n",
    "ci = stats.t.interval(confidence, len(data)-1, loc=np.mean(data), scale=sem)\n",
    "\n",
    "# MLE example: fit normal distribution\n",
    "mu_mle, std_mle = stats.norm.fit(data)\n",
    "\n",
    "# Bayesian inference with conjugate prior (Beta-Binomial)\n",
    "# Prior: Beta(α, β), Likelihood: Binomial\n",
    "# Posterior: Beta(α + successes, β + failures)\n",
    "prior_alpha, prior_beta = 1, 1  # uniform prior\n",
    "successes, failures = 7, 3\n",
    "posterior_alpha = prior_alpha + successes\n",
    "posterior_beta = prior_beta + failures\n",
    "posterior_mean = posterior_alpha / (posterior_alpha + posterior_beta)\n",
    "```\n",
    "\n",
    "**Common Interview Questions - Probability:**\n",
    "\n",
    "1. **What's the probability of getting at least one 6 in 4 dice rolls?**\n",
    "   - P(at least one 6) = 1 - P(no 6s) = 1 - (5/6)⁴ ≈ 0.518\n",
    "\n",
    "2. **Two coins: one fair, one double-headed. You pick one randomly and flip heads. What's P(fair coin)?**\n",
    "   - Using Bayes: P(fair|H) = P(H|fair)P(fair) / P(H)\n",
    "   - = (0.5 × 0.5) / (0.5 × 0.5 + 1 × 0.5) = 0.25 / 0.75 = 1/3\n",
    "\n",
    "3. **What's the expected number of coin flips to get heads?**\n",
    "   - Geometric distribution: E[X] = 1/p = 1/0.5 = 2 flips\n",
    "\n",
    "4. **Why do we use log-likelihood instead of likelihood?**\n",
    "   - Products become sums (numerically stable)\n",
    "   - Avoids underflow with many samples\n",
    "   - Easier to differentiate\n",
    "\n",
    "---\n",
    "\n",
    "### 1.11 Common Interview Questions - ML Basics\n",
    "\n",
    "1. **What's the difference between parametric and non-parametric models?**\n",
    "   - Parametric: Fixed number of parameters (Linear Regression, Neural Networks)\n",
    "   - Non-parametric: Parameters grow with data (KNN, Decision Trees)\n",
    "\n",
    "2. **What is the curse of dimensionality?**\n",
    "   - As dimensions increase, data becomes sparse\n",
    "   - Distance metrics become less meaningful\n",
    "   - Need exponentially more data\n",
    "\n",
    "3. **How do you handle imbalanced datasets?**\n",
    "   - Resampling (oversample minority, undersample majority)\n",
    "   - SMOTE (synthetic samples)\n",
    "   - Class weights in loss function\n",
    "   - Use appropriate metrics (F1, AUC, not accuracy)\n",
    "\n",
    "4. **What is data leakage?**\n",
    "   - Information from test set leaks into training\n",
    "   - Examples: scaling before split, using future data\n",
    "   - Results in overly optimistic performance\n",
    "\n",
    "5. **Generative vs Discriminative models?**\n",
    "   - Generative: Model P(x,y), can generate data (Naive Bayes, GANs)\n",
    "   - Discriminative: Model P(y|x) directly (Logistic Regression, SVM)\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: Deep Learning Fundamentals\n",
    "\n",
    "### 2.1 Neural Network Basics\n",
    "\n",
    "**Q: What is a neural network?**\n",
    "\n",
    "Composition of linear transformations and non-linear activations:\n",
    "```\n",
    "Input → Linear → Activation → Linear → Activation → ... → Output\n",
    "```\n",
    "\n",
    "**Q: Why do we need activation functions?**\n",
    "\n",
    "Without them, any depth of linear layers collapses to one linear transformation. Activations introduce non-linearity.\n",
    "\n",
    "**Q: What is backpropagation?**\n",
    "\n",
    "Algorithm to compute gradients efficiently using chain rule:\n",
    "1. Forward pass: compute outputs\n",
    "2. Backward pass: compute gradients from output to input\n",
    "3. Update weights using gradients\n",
    "\n",
    "**Code - Simple Neural Network:**\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# Manual backprop example (for understanding)\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "w = torch.tensor([0.5, 0.5], requires_grad=True)\n",
    "y = (x * w).sum()  # forward pass\n",
    "y.backward()       # backward pass\n",
    "print(f\"Gradients: x.grad={x.grad}, w.grad={w.grad}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2 Optimization\n",
    "\n",
    "**Q: Explain gradient descent variants**\n",
    "\n",
    "| Variant | Description |\n",
    "|---------|-------------|\n",
    "| Batch GD | Use all data per update (slow) |\n",
    "| Stochastic GD | Use 1 sample per update (noisy) |\n",
    "| Mini-batch GD | Use batch of samples (best of both) |\n",
    "\n",
    "**Q: What is momentum?**\n",
    "\n",
    "Accumulate velocity from past gradients to smooth updates and escape local minima.\n",
    "\n",
    "**Q: Explain Adam optimizer**\n",
    "\n",
    "Combines momentum (first moment) + adaptive learning rates (second moment). Default choice for most tasks.\n",
    "\n",
    "**Code - Optimizers:**\n",
    "```python\n",
    "import torch.optim as optim\n",
    "\n",
    "# SGD with momentum\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Adam (default choice)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "\n",
    "# AdamW (Adam with decoupled weight decay)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "# or cosine annealing\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "# In training loop:\n",
    "for epoch in range(epochs):\n",
    "    train_one_epoch()\n",
    "    scheduler.step()  # update learning rate\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2.3 Weight Initialization\n",
    "\n",
    "**Q: Why does initialization matter?**\n",
    "\n",
    "- Too small: vanishing gradients\n",
    "- Too large: exploding gradients\n",
    "- Same values: symmetry (neurons learn same thing)\n",
    "\n",
    "**Common methods:**\n",
    "- Xavier/Glorot: For tanh/sigmoid\n",
    "- He/Kaiming: For ReLU\n",
    "- Normal/Uniform with appropriate scale\n",
    "\n",
    "**Code - Weight Initialization:**\n",
    "```python\n",
    "import torch.nn.init as init\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # Xavier for tanh/sigmoid\n",
    "        init.xavier_uniform_(m.weight)\n",
    "        # He/Kaiming for ReLU\n",
    "        # init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "model.apply(init_weights)  # apply to all layers\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2.4 Batch Normalization vs Layer Normalization\n",
    "\n",
    "| | Batch Norm | Layer Norm |\n",
    "|---|---|---|\n",
    "| Normalizes over | Batch dimension | Feature dimension |\n",
    "| Depends on batch size | Yes | No |\n",
    "| Best for | CNNs | Transformers, RNNs |\n",
    "| Train/eval difference | Yes | No |\n",
    "\n",
    "**Code - Normalization:**\n",
    "```python\n",
    "# Batch Normalization (for CNNs)\n",
    "bn = nn.BatchNorm1d(num_features=64)\n",
    "bn = nn.BatchNorm2d(num_features=64)  # for conv layers\n",
    "\n",
    "# Layer Normalization (for Transformers)\n",
    "ln = nn.LayerNorm(normalized_shape=512)\n",
    "\n",
    "# In a model\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return F.relu(self.bn(self.conv(x)))\n",
    "\n",
    "# Remember: model.train() vs model.eval() affects BatchNorm!\n",
    "model.train()  # use batch statistics\n",
    "model.eval()   # use running statistics\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2.5 Recurrent Neural Networks (RNN, LSTM, GRU)\n",
    "\n",
    "**Q: What is an RNN and when do you use it?**\n",
    "\n",
    "RNNs process sequential data by maintaining a hidden state that captures information from previous time steps.\n",
    "\n",
    "**Use cases:**\n",
    "- Time series forecasting\n",
    "- Natural language processing\n",
    "- Speech recognition\n",
    "- Video analysis\n",
    "\n",
    "**Basic RNN equation:**\n",
    "$$h_t = \\tanh(W_{hh}h_{t-1} + W_{xh}x_t + b)$$\n",
    "$$y_t = W_{hy}h_t$$\n",
    "\n",
    "**Q: What is the vanishing/exploding gradient problem?**\n",
    "\n",
    "During backpropagation through time (BPTT), gradients are multiplied repeatedly:\n",
    "- **Vanishing:** Gradients → 0, early time steps don't learn\n",
    "- **Exploding:** Gradients → ∞, training becomes unstable\n",
    "\n",
    "**Solutions:**\n",
    "- LSTM/GRU architectures (gating mechanisms)\n",
    "- Gradient clipping (for exploding)\n",
    "- Skip connections\n",
    "- Proper initialization\n",
    "\n",
    "**Q: Explain LSTM (Long Short-Term Memory)**\n",
    "\n",
    "LSTM uses gates to control information flow:\n",
    "\n",
    "| Gate | Formula | Purpose |\n",
    "|------|---------|---------|\n",
    "| Forget | $f_t = \\sigma(W_f[h_{t-1}, x_t] + b_f)$ | What to forget from cell state |\n",
    "| Input | $i_t = \\sigma(W_i[h_{t-1}, x_t] + b_i)$ | What new info to store |\n",
    "| Output | $o_t = \\sigma(W_o[h_{t-1}, x_t] + b_o)$ | What to output |\n",
    "\n",
    "**Cell state update:**\n",
    "$$\\tilde{C}_t = \\tanh(W_C[h_{t-1}, x_t] + b_C)$$\n",
    "$$C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t$$\n",
    "$$h_t = o_t \\odot \\tanh(C_t)$$\n",
    "\n",
    "**Key insight:** Cell state acts as a \"highway\" for gradients, allowing long-range dependencies.\n",
    "\n",
    "**Q: Explain GRU (Gated Recurrent Unit)**\n",
    "\n",
    "GRU is a simplified LSTM with 2 gates instead of 3:\n",
    "\n",
    "| Gate | Formula | Purpose |\n",
    "|------|---------|---------|\n",
    "| Reset | $r_t = \\sigma(W_r[h_{t-1}, x_t])$ | How much past to forget |\n",
    "| Update | $z_t = \\sigma(W_z[h_{t-1}, x_t])$ | Balance old vs new |\n",
    "\n",
    "**Hidden state update:**\n",
    "$$\\tilde{h}_t = \\tanh(W[r_t \\odot h_{t-1}, x_t])$$\n",
    "$$h_t = (1 - z_t) \\odot h_{t-1} + z_t \\odot \\tilde{h}_t$$\n",
    "\n",
    "**Q: LSTM vs GRU - when to use which?**\n",
    "\n",
    "| Aspect | LSTM | GRU |\n",
    "|--------|------|-----|\n",
    "| Parameters | More (3 gates) | Fewer (2 gates) |\n",
    "| Training | Slower | Faster |\n",
    "| Long sequences | Better | Good |\n",
    "| Small datasets | May overfit | Better |\n",
    "| Default choice | Complex tasks | Start here |\n",
    "\n",
    "**Q: What is bidirectional RNN?**\n",
    "\n",
    "Processes sequence in both directions (forward and backward), capturing context from both past and future:\n",
    "- Output combines both hidden states\n",
    "- Doubles the parameters\n",
    "- Cannot be used for real-time prediction (needs future)\n",
    "\n",
    "**Code - RNN/LSTM/GRU in PyTorch:**\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Basic RNN\n",
    "rnn = nn.RNN(input_size=10, hidden_size=20, num_layers=2, batch_first=True)\n",
    "# input: (batch, seq_len, input_size)\n",
    "# output: (batch, seq_len, hidden_size), h_n: (num_layers, batch, hidden_size)\n",
    "output, h_n = rnn(x)\n",
    "\n",
    "# LSTM\n",
    "lstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=2, batch_first=True)\n",
    "# Returns output, (h_n, c_n) - note the cell state!\n",
    "output, (h_n, c_n) = lstm(x)\n",
    "\n",
    "# GRU\n",
    "gru = nn.GRU(input_size=10, hidden_size=20, num_layers=2, batch_first=True)\n",
    "output, h_n = gru(x)\n",
    "\n",
    "# Bidirectional LSTM\n",
    "bilstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=2, \n",
    "                 batch_first=True, bidirectional=True)\n",
    "# output shape: (batch, seq_len, 2*hidden_size)\n",
    "output, (h_n, c_n) = bilstm(x)\n",
    "\n",
    "\n",
    "# Complete LSTM model for sequence classification\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, \n",
    "                 n_layers=2, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, n_layers, \n",
    "                           batch_first=True, dropout=dropout, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # *2 for bidirectional\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len)\n",
    "        embedded = self.dropout(self.embedding(x))  # (batch, seq_len, embed_dim)\n",
    "        output, (h_n, c_n) = self.lstm(embedded)\n",
    "        \n",
    "        # Concatenate final forward and backward hidden states\n",
    "        # h_n shape: (n_layers*2, batch, hidden_dim) for bidirectional\n",
    "        hidden = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n",
    "        \n",
    "        return self.fc(self.dropout(hidden))\n",
    "\n",
    "\n",
    "# LSTM for sequence-to-sequence (e.g., time series)\n",
    "class LSTMSeq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, input_dim)\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "        # output: (batch, seq_len, hidden_dim)\n",
    "        predictions = self.fc(output)  # (batch, seq_len, output_dim)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "# Gradient clipping during training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for batch in dataloader:\n",
    "    optimizer.zero_grad()\n",
    "    output = model(batch.text)\n",
    "    loss = criterion(output, batch.label)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Clip gradients to prevent exploding gradients\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "# Packing sequences for variable length inputs\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "def forward_with_packing(self, x, lengths):\n",
    "    # x: padded sequences (batch, max_seq_len, input_dim)\n",
    "    # lengths: actual lengths of each sequence\n",
    "    \n",
    "    # Pack to ignore padding in LSTM computation\n",
    "    packed = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "    output, (h_n, c_n) = self.lstm(packed)\n",
    "    \n",
    "    # Unpack back to padded\n",
    "    output, _ = pad_packed_sequence(output, batch_first=True)\n",
    "    return output, h_n\n",
    "```\n",
    "\n",
    "**Common Interview Questions - RNN:**\n",
    "\n",
    "1. **Why can't standard RNNs capture long-range dependencies?**\n",
    "   - Vanishing gradients: gradients shrink exponentially over time steps\n",
    "   - Information from early steps gets \"washed out\"\n",
    "\n",
    "2. **How does LSTM solve the vanishing gradient problem?**\n",
    "   - Cell state provides a direct path for gradients (additive, not multiplicative)\n",
    "   - Gates learn what to remember/forget\n",
    "   - Gradient can flow unchanged through cell state\n",
    "\n",
    "3. **When would you use RNN vs Transformer?**\n",
    "   - RNN: Sequential processing required, limited compute, streaming data\n",
    "   - Transformer: Parallel processing, long sequences, large datasets\n",
    "   - Modern trend: Transformers dominate most NLP tasks\n",
    "\n",
    "4. **What is teacher forcing?**\n",
    "   - During training: feed ground truth as next input (not model's prediction)\n",
    "   - Speeds up training but can cause exposure bias\n",
    "   - Solution: scheduled sampling (gradually use model predictions)\n",
    "\n",
    "5. **How do you handle variable-length sequences?**\n",
    "   - Padding + masking\n",
    "   - Pack sequences (PyTorch's pack_padded_sequence)\n",
    "   - Truncate to fixed length\n",
    "\n",
    "---\n",
    "\n",
    "## Part 3: PyTorch Fundamentals\n",
    "\n",
    "### 1.1 Tensors - The Foundation\n",
    "\n",
    "**Q: What is a tensor and why is it important?**\n",
    "\n",
    "A tensor is PyTorch's fundamental data structure - a multi-dimensional array that can hold numbers:\n",
    "- 0D tensor = scalar (single number)\n",
    "- 1D tensor = vector (list of numbers)\n",
    "- 2D tensor = matrix (table of numbers)\n",
    "- 3D+ tensor = higher dimensions\n",
    "\n",
    "**Key advantages over NumPy arrays:**\n",
    "1. GPU acceleration for massive speedups\n",
    "2. Automatic differentiation for training neural networks\n",
    "\n",
    "**Common tensor properties:**\n",
    "- `.shape` or `.size()` - dimensions\n",
    "- `.dtype` - data type (float32, int64, etc.)\n",
    "- `.device` - CPU or GPU location\n",
    "- `.requires_grad` - gradient tracking flag\n",
    "\n",
    "**Q: Explain reshape vs view**\n",
    "\n",
    "- `.reshape()` - More flexible, may copy data if needed\n",
    "- `.view()` - Shares memory with original (faster but requires contiguous memory)\n",
    "- Use `-1` to auto-infer one dimension: `tensor.reshape(-1, 4)`\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 Device Management\n",
    "\n",
    "**Q: How do you handle CPU/GPU computation?**\n",
    "\n",
    "```python\n",
    "# Check availability and set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create tensor on device\n",
    "x = torch.tensor([1, 2, 3], device=device)\n",
    "\n",
    "# Move existing tensor\n",
    "x = x.to(device)  # or x.cuda() / x.cpu()\n",
    "```\n",
    "\n",
    "**Critical rule:** All tensors in an operation must be on the same device!\n",
    "\n",
    "**Q: When to use GPU vs CPU?**\n",
    "- GPU: Training large models, big batches, production inference\n",
    "- CPU: Small models, debugging, data preprocessing\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3 Automatic Differentiation (Autograd)\n",
    "\n",
    "**Q: Explain requires_grad and the computation graph**\n",
    "\n",
    "`requires_grad=True` tells PyTorch to track operations for gradient computation. PyTorch builds a dynamic computation graph during forward pass.\n",
    "\n",
    "```python\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = x ** 2  # y has grad_fn pointing to PowBackward\n",
    "y.backward()  # Compute gradients\n",
    "print(x.grad)  # tensor([4.0]) - derivative of x² is 2x\n",
    "```\n",
    "\n",
    "**Q: What happens during backward()?**\n",
    "\n",
    "1. Traverses computation graph from output to inputs\n",
    "2. Applies chain rule at each operation\n",
    "3. Stores gradients in `.grad` attributes of leaf tensors\n",
    "4. Graph is freed after backward (unless `retain_graph=True`)\n",
    "\n",
    "**Q: Why do gradients accumulate?**\n",
    "\n",
    "By default, `.backward()` adds to existing gradients. Must call `optimizer.zero_grad()` before each backward pass to clear old gradients.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.4 nn.Module - Building Neural Networks\n",
    "\n",
    "**Q: Explain the nn.Module pattern**\n",
    "\n",
    "```python\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # Always call this first!\n",
    "        self.layer1 = nn.Linear(10, 5)\n",
    "        self.layer2 = nn.Linear(5, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        return self.layer2(x)\n",
    "```\n",
    "\n",
    "**Key methods:**\n",
    "- `.parameters()` - Get all learnable parameters\n",
    "- `.to(device)` - Move model to CPU/GPU\n",
    "- `.train()` / `.eval()` - Set training/evaluation mode\n",
    "- `.state_dict()` - Get model weights for saving\n",
    "\n",
    "**Q: nn.Parameter vs regular tensor?**\n",
    "\n",
    "`nn.Parameter` is automatically registered, included in `.parameters()`, and saved in state_dict. Regular tensors are not tracked.\n",
    "\n",
    "**Code - Saving and Loading Models:**\n",
    "```python\n",
    "# Save model weights\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# Load model weights\n",
    "model = MyNetwork()\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Save entire model (less flexible)\n",
    "torch.save(model, 'full_model.pth')\n",
    "model = torch.load('full_model.pth')\n",
    "\n",
    "# Save checkpoint (for resuming training)\n",
    "checkpoint = {\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss,\n",
    "}\n",
    "torch.save(checkpoint, 'checkpoint.pth')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1.5 Activation Functions\n",
    "\n",
    "**Q: Compare ReLU, GeLU, and Softmax**\n",
    "\n",
    "| Function | Formula | Use Case |\n",
    "|----------|---------|----------|\n",
    "| ReLU | max(0, x) | Hidden layers (default) |\n",
    "| GeLU | x * Φ(x) | Transformers (BERT, GPT) |\n",
    "| Softmax | exp(xi)/Σexp(xj) | Output layer (classification) |\n",
    "\n",
    "**Q: Why are activation functions necessary?**\n",
    "\n",
    "Without them, stacked linear layers collapse to a single linear transformation. Activations introduce non-linearity, enabling networks to learn complex patterns.\n",
    "\n",
    "**Q: What is the dying ReLU problem?**\n",
    "\n",
    "If a neuron's output is always negative, ReLU outputs zero and gradient is zero - the neuron stops learning. Solutions: LeakyReLU, GeLU, or careful initialization.\n",
    "\n",
    "**Code - Activation Functions:**\n",
    "```python\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ReLU\n",
    "x = F.relu(x)\n",
    "# or as module: nn.ReLU()\n",
    "\n",
    "# LeakyReLU (fixes dying ReLU)\n",
    "x = F.leaky_relu(x, negative_slope=0.01)\n",
    "\n",
    "# GeLU (used in transformers)\n",
    "x = F.gelu(x)\n",
    "\n",
    "# Softmax (for classification output)\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "# Log-Softmax (numerically stable for NLL loss)\n",
    "log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "# Sigmoid (binary classification)\n",
    "prob = torch.sigmoid(x)\n",
    "\n",
    "# Tanh\n",
    "x = torch.tanh(x)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1.6 Loss Functions\n",
    "\n",
    "**Q: When to use MSE vs Cross-Entropy?**\n",
    "\n",
    "- **MSE (Mean Squared Error):** Regression tasks (predicting continuous values)\n",
    "- **Cross-Entropy:** Classification tasks (predicting categories)\n",
    "\n",
    "**Q: Why does CrossEntropyLoss expect logits, not probabilities?**\n",
    "\n",
    "For numerical stability. Computing softmax then log can cause issues. CrossEntropyLoss combines them efficiently using the log-sum-exp trick.\n",
    "\n",
    "**Code - Loss Functions:**\n",
    "```python\n",
    "# Classification - Cross Entropy (expects logits, not probabilities!)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(logits, labels)  # logits: (batch, classes), labels: (batch,)\n",
    "\n",
    "# Binary Classification\n",
    "criterion = nn.BCEWithLogitsLoss()  # includes sigmoid\n",
    "loss = criterion(logits, labels.float())\n",
    "\n",
    "# Regression - MSE\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(predictions, targets)\n",
    "\n",
    "# Regression - MAE (L1)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# With class weights (for imbalanced data)\n",
    "weights = torch.tensor([1.0, 2.0, 3.0])  # weight per class\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "# Label smoothing\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1.7 The Training Loop\n",
    "\n",
    "**Q: Walk through a complete training step**\n",
    "\n",
    "```python\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        # 1. Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 2. Forward pass\n",
    "        predictions = model(batch_x)\n",
    "        loss = criterion(predictions, batch_y)\n",
    "        \n",
    "        # 3. Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # 4. Update parameters\n",
    "        optimizer.step()\n",
    "```\n",
    "\n",
    "**Q: Why is the order important?**\n",
    "\n",
    "- `zero_grad()` before `backward()` - prevents gradient accumulation\n",
    "- `backward()` before `step()` - gradients must exist before updating\n",
    "- `step()` uses gradients to update parameters\n",
    "\n",
    "---\n",
    "\n",
    "### 1.8 Optimizers\n",
    "\n",
    "**Q: Compare SGD and Adam**\n",
    "\n",
    "| Aspect | SGD | Adam |\n",
    "|--------|-----|------|\n",
    "| Learning rate | Same for all params | Adaptive per param |\n",
    "| Momentum | Optional | Built-in |\n",
    "| Typical LR | 0.01-0.1 | 0.001 |\n",
    "| Use case | Simple problems | Default choice |\n",
    "\n",
    "**Q: What is AdamW?**\n",
    "\n",
    "Adam with decoupled weight decay. Standard L2 regularization in Adam doesn't work well because it's scaled by adaptive learning rate. AdamW fixes this.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 4: Convolutional Neural Networks (CNNs)\n",
    "\n",
    "### 10.1 Convolution Operations\n",
    "\n",
    "**Q: What is a convolution and why use it for images?**\n",
    "\n",
    "Convolution slides a kernel (filter) over input, computing element-wise multiplication and sum at each position.\n",
    "\n",
    "**Key properties:**\n",
    "- **Parameter sharing:** Same kernel applied everywhere (fewer parameters)\n",
    "- **Translation equivariance:** Detects features regardless of position\n",
    "- **Local connectivity:** Each output depends on local region only\n",
    "\n",
    "**Convolution formula:**\n",
    "$$(I * K)(i,j) = \\sum_m \\sum_n I(i+m, j+n) \\cdot K(m,n)$$\n",
    "\n",
    "**Output size formula:**\n",
    "$$\\text{out} = \\left\\lfloor\\frac{\\text{in} + 2p - k}{s}\\right\\rfloor + 1$$\n",
    "\n",
    "Where: p = padding, k = kernel size, s = stride\n",
    "\n",
    "**Q: Explain padding and stride**\n",
    "\n",
    "| Concept | Description | Effect |\n",
    "|---------|-------------|--------|\n",
    "| Padding | Add zeros around input | Preserves spatial size |\n",
    "| Stride | Step size of kernel | Reduces spatial size |\n",
    "| Valid padding | No padding | Output smaller than input |\n",
    "| Same padding | Pad to keep size | Output = Input (stride=1) |\n",
    "\n",
    "**Q: What is pooling?**\n",
    "\n",
    "Downsampling operation that reduces spatial dimensions:\n",
    "- **Max Pooling:** Takes maximum value in window (most common)\n",
    "- **Average Pooling:** Takes average value in window\n",
    "- **Global Average Pooling:** Average entire feature map to single value\n",
    "\n",
    "**Benefits:** Reduces computation, provides translation invariance, prevents overfitting\n",
    "\n",
    "**Q: What is the receptive field?**\n",
    "\n",
    "The region of input that affects a particular output neuron. Grows with:\n",
    "- More layers (depth)\n",
    "- Larger kernels\n",
    "- Larger strides\n",
    "- Dilated convolutions\n",
    "\n",
    "**Code - CNN Components:**\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Basic convolution\n",
    "conv = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, \n",
    "                 stride=1, padding=1)  # same padding\n",
    "\n",
    "# Pooling\n",
    "maxpool = nn.MaxPool2d(kernel_size=2, stride=2)  # halves spatial dims\n",
    "avgpool = nn.AdaptiveAvgPool2d((1, 1))  # global average pooling\n",
    "\n",
    "# Transposed convolution (upsampling)\n",
    "deconv = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "\n",
    "# Dilated convolution (larger receptive field)\n",
    "dilated_conv = nn.Conv2d(64, 64, kernel_size=3, padding=2, dilation=2)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 10.2 Classic CNN Architectures\n",
    "\n",
    "**Q: Describe key CNN architectures**\n",
    "\n",
    "| Architecture | Year | Key Innovation | Depth |\n",
    "|--------------|------|----------------|-------|\n",
    "| LeNet | 1998 | First successful CNN | 5 |\n",
    "| AlexNet | 2012 | ReLU, Dropout, GPU | 8 |\n",
    "| VGG | 2014 | Small 3x3 kernels, depth | 16-19 |\n",
    "| GoogLeNet | 2014 | Inception modules | 22 |\n",
    "| ResNet | 2015 | Skip connections | 50-152 |\n",
    "| DenseNet | 2017 | Dense connections | 121-264 |\n",
    "| EfficientNet | 2019 | Compound scaling | Variable |\n",
    "\n",
    "**Q: Explain ResNet and skip connections**\n",
    "\n",
    "Skip connections add input directly to output: $y = F(x) + x$\n",
    "\n",
    "**Why it works:**\n",
    "- Easier to learn residual F(x) = H(x) - x than full mapping H(x)\n",
    "- Gradients flow directly through skip connections\n",
    "- Enables training very deep networks (100+ layers)\n",
    "- Identity mapping is easy to learn (just set F(x) = 0)\n",
    "\n",
    "**Q: What is the Inception module?**\n",
    "\n",
    "Parallel convolutions with different kernel sizes (1x1, 3x3, 5x5) + pooling, concatenated together. Captures multi-scale features efficiently.\n",
    "\n",
    "**Code - CNN Architectures:**\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Simple CNN for image classification\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 32x32 -> 16x16\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 16x16 -> 8x8\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # 8x8 -> 4x4\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "# ResNet Block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Skip connection with projection if dimensions change\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)  # skip connection\n",
    "        return F.relu(out)\n",
    "\n",
    "\n",
    "# Using pretrained models\n",
    "from torchvision import models\n",
    "\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "# Replace final layer for transfer learning\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, num_classes)\n",
    "\n",
    "# Freeze early layers\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in resnet.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 10.3 Common CNN Interview Questions\n",
    "\n",
    "1. **Why use 3x3 kernels instead of larger ones?**\n",
    "   - Two 3x3 = one 5x5 receptive field, but fewer parameters\n",
    "   - More non-linearities (more ReLUs)\n",
    "   - VGG showed this works better\n",
    "\n",
    "2. **What is 1x1 convolution used for?**\n",
    "   - Channel-wise pooling (reduce/increase channels)\n",
    "   - Add non-linearity without changing spatial size\n",
    "   - Used in Inception, ResNet bottleneck\n",
    "\n",
    "3. **How do you handle different input sizes?**\n",
    "   - Global Average Pooling (removes spatial dimensions)\n",
    "   - Adaptive pooling to fixed size\n",
    "   - Fully convolutional networks\n",
    "\n",
    "4. **What causes checkerboard artifacts in generated images?**\n",
    "   - Transposed convolution with stride > 1\n",
    "   - Solution: resize + convolution, or careful kernel size\n",
    "\n",
    "---\n",
    "\n",
    "## Part 5: LLM & Transformer Concepts\n",
    "\n",
    "### 2.1 Attention Mechanism\n",
    "\n",
    "**Q: Explain the attention formula**\n",
    "\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
    "\n",
    "- **Q (Query):** What am I looking for?\n",
    "- **K (Key):** What do I contain?\n",
    "- **V (Value):** What information do I provide?\n",
    "- **√d_k scaling:** Prevents softmax saturation for large dimensions\n",
    "\n",
    "**Q: Why scale by √d_k?**\n",
    "\n",
    "If Q and K have variance 1, their dot product has variance d_k. Dividing by √d_k normalizes back to variance 1, keeping softmax in a good gradient region.\n",
    "\n",
    "**Q: What is multi-head attention?**\n",
    "\n",
    "Run multiple attention operations in parallel, each learning different patterns:\n",
    "- Head 1: syntactic relationships\n",
    "- Head 2: semantic relationships\n",
    "- Head 3: positional patterns\n",
    "\n",
    "Formula: MultiHead(Q,K,V) = Concat(head₁,...,headₕ)W^O\n",
    "\n",
    "**Code - Multi-Head Attention:**\n",
    "```python\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        batch_size = q.size(0)\n",
    "        \n",
    "        # Linear projections and reshape to (batch, heads, seq, d_k)\n",
    "        Q = self.W_q(q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(k).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(v).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        out = torch.matmul(attn, V)\n",
    "        out = out.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_k)\n",
    "        return self.W_o(out)\n",
    "\n",
    "# Using PyTorch's built-in\n",
    "mha = nn.MultiheadAttention(embed_dim=512, num_heads=8, batch_first=True)\n",
    "output, attn_weights = mha(query, key, value, attn_mask=mask)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2 Self-Attention vs Cross-Attention\n",
    "\n",
    "| Type | Q, K, V Source | Use Case |\n",
    "|------|---------------|----------|\n",
    "| Self-Attention | Same sequence | Encoder, decoder self-attention |\n",
    "| Cross-Attention | Q: target, K/V: source | Encoder-decoder connection |\n",
    "\n",
    "---\n",
    "\n",
    "### 2.3 Transformer Architecture\n",
    "\n",
    "**Q: Describe the transformer encoder block**\n",
    "\n",
    "```\n",
    "Input → LayerNorm → Multi-Head Self-Attention → + (residual)\n",
    "                                                ↓\n",
    "      → LayerNorm → Feed-Forward Network → + (residual) → Output\n",
    "```\n",
    "\n",
    "**Q: What is the FFN and why is it important?**\n",
    "\n",
    "Position-wise Feed-Forward Network: FFN(x) = ReLU(xW₁)W₂\n",
    "\n",
    "- Provides non-linearity (attention is linear in V)\n",
    "- Typically 4x expansion (d_model → 4*d_model → d_model)\n",
    "- Contains 2/3 of transformer parameters!\n",
    "\n",
    "**Q: Pre-norm vs Post-norm?**\n",
    "\n",
    "- **Post-norm (original):** LayerNorm(x + Sublayer(x))\n",
    "- **Pre-norm (modern):** x + Sublayer(LayerNorm(x))\n",
    "\n",
    "Pre-norm is more stable for training deep networks.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.4 BERT vs GPT\n",
    "\n",
    "| Aspect | BERT | GPT |\n",
    "|--------|------|-----|\n",
    "| Architecture | Encoder-only | Decoder-only |\n",
    "| Attention | Bidirectional | Causal (left-to-right) |\n",
    "| Pre-training | Masked LM + NSP | Next token prediction |\n",
    "| Strength | Understanding | Generation |\n",
    "\n",
    "**Q: Why can't BERT generate text?**\n",
    "\n",
    "BERT sees the entire sequence during training (bidirectional). At generation time, future tokens don't exist, so BERT can't predict autoregressively.\n",
    "\n",
    "**Q: What is causal masking?**\n",
    "\n",
    "A lower triangular mask that prevents tokens from attending to future positions. Essential for autoregressive generation.\n",
    "\n",
    "**Code - Causal Mask:**\n",
    "```python\n",
    "def create_causal_mask(seq_len):\n",
    "    \"\"\"Create lower triangular mask for autoregressive attention\"\"\"\n",
    "    mask = torch.tril(torch.ones(seq_len, seq_len))\n",
    "    return mask  # 1s where attention is allowed, 0s where blocked\n",
    "\n",
    "# Example: seq_len=4\n",
    "# [[1, 0, 0, 0],\n",
    "#  [1, 1, 0, 0],\n",
    "#  [1, 1, 1, 0],\n",
    "#  [1, 1, 1, 1]]\n",
    "\n",
    "# For nn.MultiheadAttention (expects additive mask)\n",
    "def create_causal_mask_additive(seq_len):\n",
    "    mask = torch.triu(torch.ones(seq_len, seq_len) * float('-inf'), diagonal=1)\n",
    "    return mask\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2.5 Positional Encoding\n",
    "\n",
    "**Q: Why do transformers need positional encoding?**\n",
    "\n",
    "Transformers process all tokens in parallel with no inherent position awareness. Without positional info, \"cat sat mat\" and \"mat sat cat\" would be identical.\n",
    "\n",
    "**Q: Compare positional encoding methods**\n",
    "\n",
    "| Method | Learned? | Extrapolation | Used In |\n",
    "|--------|----------|---------------|---------|\n",
    "| Sinusoidal | No | Good | Original Transformer |\n",
    "| Learned | Yes | Poor | BERT, GPT-2 |\n",
    "| RoPE | No | Excellent | LLaMA, Mistral |\n",
    "\n",
    "**RoPE (Rotary Position Embeddings):** Encodes position by rotating Q and K vectors. Naturally captures relative positions.\n",
    "\n",
    "**Code - Positional Encoding:**\n",
    "```python\n",
    "import math\n",
    "\n",
    "class SinusoidalPositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n",
    "                            (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))  # (1, max_len, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "# Learned positional embeddings (like BERT/GPT-2)\n",
    "class LearnedPositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super().__init__()\n",
    "        self.pos_embed = nn.Embedding(max_len, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        positions = torch.arange(x.size(1), device=x.device)\n",
    "        return x + self.pos_embed(positions)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2.6 Modern LLM Techniques\n",
    "\n",
    "**Q: What is RMSNorm and why use it?**\n",
    "\n",
    "Simplified LayerNorm without mean subtraction:\n",
    "$$\\text{RMSNorm}(x) = \\gamma \\cdot \\frac{x}{\\text{RMS}(x)}$$\n",
    "\n",
    "~10% faster, fewer parameters, works just as well.\n",
    "\n",
    "**Q: What is SwiGLU?**\n",
    "\n",
    "Gated activation: SwiGLU(x) = Swish(xW₁) ⊙ xW₃\n",
    "\n",
    "Better than ReLU/GeLU, used in LLaMA, PaLM.\n",
    "\n",
    "**Q: Explain Grouped Query Attention (GQA)**\n",
    "\n",
    "Multiple Q heads share K/V heads to reduce KV cache size:\n",
    "- MHA: 8 Q heads, 8 KV heads\n",
    "- GQA: 8 Q heads, 2 KV heads (4x smaller cache)\n",
    "\n",
    "Used in LLaMA 2 70B, Mistral.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.7 Efficient Attention\n",
    "\n",
    "**Q: Why is attention O(n²)?**\n",
    "\n",
    "Computing QK^T requires n² dot products. For 100K tokens, that's 10 billion operations per layer!\n",
    "\n",
    "**Q: What is Flash Attention?**\n",
    "\n",
    "IO-aware attention that never materializes the full n×n matrix:\n",
    "- Tiles computation into blocks\n",
    "- Computes in fast SRAM\n",
    "- 2-4x faster, 5-20x less memory\n",
    "- Exact computation (not approximation)\n",
    "\n",
    "**Q: What is sliding window attention?**\n",
    "\n",
    "Each token only attends to W previous tokens. With L layers, effective context is L×W. Mistral: 32 layers × 4096 = 131K effective context.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.8 Mixture of Experts (MoE)\n",
    "\n",
    "**Q: Explain MoE architecture**\n",
    "\n",
    "Replace FFN with multiple \"expert\" FFNs. Router selects top-k experts per token.\n",
    "\n",
    "- Mixtral 8x7B: 47B total params, only 13B active\n",
    "- More capacity without proportional compute increase\n",
    "\n",
    "**Q: What is load balancing loss?**\n",
    "\n",
    "Auxiliary loss to prevent all tokens going to one expert:\n",
    "$$\\mathcal{L}_{aux} = \\alpha \\cdot n \\cdot \\sum_i f_i \\cdot P_i$$\n",
    "\n",
    "---\n",
    "\n",
    "### 2.9 Fine-Tuning Techniques\n",
    "\n",
    "**Q: What is LoRA?**\n",
    "\n",
    "Low-Rank Adaptation: Instead of updating W directly, decompose update as W' = W + BA where B and A are low-rank matrices.\n",
    "\n",
    "- Rank 8: 256x fewer parameters\n",
    "- Can merge into weights for zero inference overhead\n",
    "\n",
    "**Q: What is QLoRA?**\n",
    "\n",
    "LoRA + 4-bit quantization:\n",
    "- Base model quantized to 4-bit\n",
    "- LoRA adapters in FP16\n",
    "- Enables 7B+ models on consumer GPUs\n",
    "\n",
    "**Code - LoRA Concept:**\n",
    "```python\n",
    "class LoRALinear(nn.Module):\n",
    "    \"\"\"Low-Rank Adaptation layer\"\"\"\n",
    "    def __init__(self, original_layer, rank=8, alpha=16):\n",
    "        super().__init__()\n",
    "        self.original = original_layer\n",
    "        self.original.weight.requires_grad = False  # freeze original\n",
    "        \n",
    "        in_features = original_layer.in_features\n",
    "        out_features = original_layer.out_features\n",
    "        \n",
    "        # Low-rank matrices\n",
    "        self.lora_A = nn.Parameter(torch.randn(in_features, rank) * 0.01)\n",
    "        self.lora_B = nn.Parameter(torch.zeros(rank, out_features))\n",
    "        self.scale = alpha / rank\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Original output + low-rank update\n",
    "        return self.original(x) + (x @ self.lora_A @ self.lora_B) * self.scale\n",
    "\n",
    "# Apply LoRA to a model\n",
    "def apply_lora(model, rank=8):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear) and 'attention' in name:\n",
    "            parent = get_parent_module(model, name)\n",
    "            setattr(parent, name.split('.')[-1], LoRALinear(module, rank))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2.10 Training LLMs\n",
    "\n",
    "**Q: What learning rate schedule is used?**\n",
    "\n",
    "Linear warmup + cosine decay:\n",
    "- Warmup: 1-10% of training\n",
    "- Peak LR: 1e-4 to 6e-4\n",
    "- Decay to 10% of peak\n",
    "\n",
    "**Q: Why gradient clipping?**\n",
    "\n",
    "Transformers can have exploding gradients. Clip norm to 1.0 to stabilize training.\n",
    "\n",
    "**Q: What is the KV cache?**\n",
    "\n",
    "During generation, cache K and V from previous tokens to avoid recomputation. Reduces per-token compute from O(n²) to O(n).\n",
    "\n",
    "**Code - Training LLM Utilities:**\n",
    "```python\n",
    "# Learning rate schedule with warmup\n",
    "def get_lr(step, d_model, warmup_steps=4000):\n",
    "    \"\"\"Transformer learning rate schedule\"\"\"\n",
    "    return d_model ** -0.5 * min(step ** -0.5, step * warmup_steps ** -1.5)\n",
    "\n",
    "# Gradient clipping\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "# Mixed precision training\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()\n",
    "for batch in dataloader:\n",
    "    optimizer.zero_grad()\n",
    "    with autocast():\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, targets)\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "# Gradient accumulation (for larger effective batch size)\n",
    "accumulation_steps = 4\n",
    "for i, batch in enumerate(dataloader):\n",
    "    loss = model(batch) / accumulation_steps\n",
    "    loss.backward()\n",
    "    if (i + 1) % accumulation_steps == 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Part 6: Generative Models\n",
    "\n",
    "### 11.1 Variational Autoencoders (VAE)\n",
    "\n",
    "**Q: Explain the VAE architecture**\n",
    "\n",
    "VAE learns a latent representation by:\n",
    "1. **Encoder:** Maps input x to distribution parameters (μ, σ)\n",
    "2. **Sampling:** z ~ N(μ, σ²) using reparameterization trick\n",
    "3. **Decoder:** Reconstructs x from z\n",
    "\n",
    "**Loss function:**\n",
    "$$\\mathcal{L} = \\underbrace{\\mathbb{E}_{q(z|x)}[\\log p(x|z)]}_{\\text{Reconstruction}} - \\underbrace{D_{KL}(q(z|x) || p(z))}_{\\text{Regularization}}$$\n",
    "\n",
    "**Q: What is the reparameterization trick?**\n",
    "\n",
    "Instead of sampling z ~ N(μ, σ²) directly (non-differentiable), we:\n",
    "1. Sample ε ~ N(0, 1)\n",
    "2. Compute z = μ + σ * ε\n",
    "\n",
    "This allows gradients to flow through μ and σ.\n",
    "\n",
    "**Code - VAE:**\n",
    "```python\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.fc_mu(h), self.fc_var(h)\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "\n",
    "def vae_loss(recon_x, x, mu, log_var):\n",
    "    recon_loss = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return recon_loss + kl_loss\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 11.2 Generative Adversarial Networks (GANs)\n",
    "\n",
    "**Q: Explain the GAN framework**\n",
    "\n",
    "Two networks competing:\n",
    "- **Generator G:** Creates fake samples from noise z\n",
    "- **Discriminator D:** Distinguishes real from fake\n",
    "\n",
    "**Minimax objective:**\n",
    "$$\\min_G \\max_D \\mathbb{E}_{x \\sim p_{data}}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z}[\\log(1 - D(G(z)))]$$\n",
    "\n",
    "**Training alternates:**\n",
    "1. Train D to maximize: correctly classify real/fake\n",
    "2. Train G to minimize: fool D (make D(G(z)) → 1)\n",
    "\n",
    "**Q: What are common GAN training problems?**\n",
    "\n",
    "| Problem | Description | Solution |\n",
    "|---------|-------------|----------|\n",
    "| Mode collapse | G produces limited variety | Minibatch discrimination, unrolled GAN |\n",
    "| Vanishing gradients | D too strong, G gets no signal | Wasserstein loss, label smoothing |\n",
    "| Training instability | Oscillating losses | Spectral normalization, progressive growing |\n",
    "| Non-convergence | Never reaches equilibrium | Two-timescale update, careful hyperparams |\n",
    "\n",
    "**Code - Simple GAN:**\n",
    "```python\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_shape):\n",
    "        super().__init__()\n",
    "        self.img_shape = img_shape\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        return img.view(img.size(0), *self.img_shape)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        return self.model(img.view(img.size(0), -1))\n",
    "\n",
    "# Training loop\n",
    "for real_imgs in dataloader:\n",
    "    # Train Discriminator\n",
    "    z = torch.randn(batch_size, latent_dim)\n",
    "    fake_imgs = generator(z)\n",
    "    \n",
    "    real_loss = F.binary_cross_entropy(discriminator(real_imgs), torch.ones(batch_size, 1))\n",
    "    fake_loss = F.binary_cross_entropy(discriminator(fake_imgs.detach()), torch.zeros(batch_size, 1))\n",
    "    d_loss = (real_loss + fake_loss) / 2\n",
    "    \n",
    "    optimizer_D.zero_grad()\n",
    "    d_loss.backward()\n",
    "    optimizer_D.step()\n",
    "    \n",
    "    # Train Generator\n",
    "    z = torch.randn(batch_size, latent_dim)\n",
    "    fake_imgs = generator(z)\n",
    "    g_loss = F.binary_cross_entropy(discriminator(fake_imgs), torch.ones(batch_size, 1))\n",
    "    \n",
    "    optimizer_G.zero_grad()\n",
    "    g_loss.backward()\n",
    "    optimizer_G.step()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 11.3 Diffusion Models\n",
    "\n",
    "**Q: Explain how diffusion models work**\n",
    "\n",
    "Two processes:\n",
    "1. **Forward (diffusion):** Gradually add noise to data over T steps\n",
    "2. **Reverse (denoising):** Learn to remove noise step by step\n",
    "\n",
    "**Forward process:**\n",
    "$$q(x_t|x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1-\\beta_t}x_{t-1}, \\beta_t I)$$\n",
    "\n",
    "**Training objective:** Predict the noise added at each step\n",
    "$$\\mathcal{L} = \\mathbb{E}_{t, x_0, \\epsilon}[||\\epsilon - \\epsilon_\\theta(x_t, t)||^2]$$\n",
    "\n",
    "**Sampling:** Start from noise, iteratively denoise\n",
    "\n",
    "**Q: Why are diffusion models better than GANs?**\n",
    "\n",
    "| Aspect | Diffusion | GAN |\n",
    "|--------|-----------|-----|\n",
    "| Training | Stable (simple MSE loss) | Unstable (adversarial) |\n",
    "| Mode coverage | Better diversity | Mode collapse risk |\n",
    "| Sample quality | State-of-the-art | Good but less consistent |\n",
    "| Speed | Slow (many steps) | Fast (single forward pass) |\n",
    "| Controllability | Easy (classifier guidance) | Harder |\n",
    "\n",
    "**Code - Simple Diffusion Model:**\n",
    "```python\n",
    "class SimpleDiffusion:\n",
    "    def __init__(self, num_timesteps=1000, beta_start=1e-4, beta_end=0.02):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps)\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alpha_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "    \n",
    "    def add_noise(self, x_0, t, noise=None):\n",
    "        \"\"\"Forward process: add noise to x_0\"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_0)\n",
    "        \n",
    "        sqrt_alpha_cumprod = self.alpha_cumprod[t].sqrt().view(-1, 1, 1, 1)\n",
    "        sqrt_one_minus = (1 - self.alpha_cumprod[t]).sqrt().view(-1, 1, 1, 1)\n",
    "        \n",
    "        return sqrt_alpha_cumprod * x_0 + sqrt_one_minus * noise\n",
    "    \n",
    "    def sample(self, model, shape):\n",
    "        \"\"\"Reverse process: denoise from pure noise\"\"\"\n",
    "        x = torch.randn(shape)\n",
    "        \n",
    "        for t in reversed(range(self.num_timesteps)):\n",
    "            t_batch = torch.full((shape[0],), t, dtype=torch.long)\n",
    "            predicted_noise = model(x, t_batch)\n",
    "            \n",
    "            alpha = self.alphas[t]\n",
    "            alpha_cumprod = self.alpha_cumprod[t]\n",
    "            beta = self.betas[t]\n",
    "            \n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(x)\n",
    "            else:\n",
    "                noise = 0\n",
    "            \n",
    "            x = (1 / alpha.sqrt()) * (x - (beta / (1 - alpha_cumprod).sqrt()) * predicted_noise)\n",
    "            x = x + beta.sqrt() * noise\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Training\n",
    "diffusion = SimpleDiffusion()\n",
    "for x_0 in dataloader:\n",
    "    t = torch.randint(0, diffusion.num_timesteps, (batch_size,))\n",
    "    noise = torch.randn_like(x_0)\n",
    "    x_t = diffusion.add_noise(x_0, t, noise)\n",
    "    \n",
    "    predicted_noise = model(x_t, t)\n",
    "    loss = F.mse_loss(predicted_noise, noise)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Part 7: Graph Neural Networks (GNNs)\n",
    "\n",
    "### 12.1 Graph Basics\n",
    "\n",
    "**Q: When do you use GNNs?**\n",
    "\n",
    "When data has graph structure:\n",
    "- Social networks (users = nodes, friendships = edges)\n",
    "- Molecules (atoms = nodes, bonds = edges)\n",
    "- Knowledge graphs\n",
    "- Recommendation systems\n",
    "- Traffic networks\n",
    "\n",
    "**Q: What is message passing?**\n",
    "\n",
    "Core GNN operation:\n",
    "1. **Aggregate:** Collect messages from neighbors\n",
    "2. **Update:** Combine with node's own features\n",
    "\n",
    "$$h_v^{(k+1)} = \\text{UPDATE}^{(k)}\\left(h_v^{(k)}, \\text{AGGREGATE}^{(k)}(\\{h_u^{(k)} : u \\in \\mathcal{N}(v)\\})\\right)$$\n",
    "\n",
    "### 12.2 GNN Architectures\n",
    "\n",
    "**Q: Compare GCN, GAT, and GraphSAGE**\n",
    "\n",
    "| Model | Aggregation | Key Feature |\n",
    "|-------|-------------|-------------|\n",
    "| GCN | Mean (normalized) | Spectral-based, simple |\n",
    "| GAT | Attention-weighted | Learns neighbor importance |\n",
    "| GraphSAGE | Sample + aggregate | Inductive, scalable |\n",
    "\n",
    "**GCN layer:**\n",
    "$$H^{(l+1)} = \\sigma(\\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}H^{(l)}W^{(l)})$$\n",
    "\n",
    "Where $\\tilde{A} = A + I$ (add self-loops), $\\tilde{D}$ is degree matrix\n",
    "\n",
    "**Code - GNN with PyTorch Geometric:**\n",
    "```python\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Create graph data\n",
    "edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.randn(3, 16)  # 3 nodes, 16 features\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# GCN Model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# GAT Model (with attention)\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=8):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# GraphSAGE (inductive learning)\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 12.3 GNN Tasks and Challenges\n",
    "\n",
    "**Q: What are the main GNN tasks?**\n",
    "\n",
    "| Task | Level | Example |\n",
    "|------|-------|---------|\n",
    "| Node classification | Node | Predict user interests |\n",
    "| Link prediction | Edge | Recommend friends |\n",
    "| Graph classification | Graph | Predict molecule property |\n",
    "| Node clustering | Node | Community detection |\n",
    "\n",
    "**Q: What is over-smoothing in GNNs?**\n",
    "\n",
    "With many layers, all node representations converge to similar values.\n",
    "- Caused by repeated averaging over neighbors\n",
    "- Solutions: Skip connections, dropout, fewer layers, jumping knowledge\n",
    "\n",
    "**Q: Transductive vs Inductive learning?**\n",
    "\n",
    "| | Transductive | Inductive |\n",
    "|---|---|---|\n",
    "| Test nodes | Seen during training | Unseen |\n",
    "| Example | GCN | GraphSAGE |\n",
    "| Use case | Fixed graph | Growing graph |\n",
    "\n",
    "---\n",
    "\n",
    "## Part 8: Natural Language Processing Basics\n",
    "\n",
    "### 13.1 Text Preprocessing\n",
    "\n",
    "**Q: What are the steps in NLP preprocessing?**\n",
    "\n",
    "1. **Tokenization:** Split text into tokens (words, subwords, characters)\n",
    "2. **Lowercasing:** Normalize case (optional)\n",
    "3. **Stop word removal:** Remove common words (optional)\n",
    "4. **Stemming/Lemmatization:** Reduce to root form\n",
    "5. **Encoding:** Convert to numbers\n",
    "\n",
    "**Q: Compare tokenization approaches**\n",
    "\n",
    "| Method | Granularity | Pros | Cons |\n",
    "|--------|-------------|------|------|\n",
    "| Word | Words | Interpretable | Large vocab, OOV |\n",
    "| Character | Characters | Small vocab, no OOV | Long sequences |\n",
    "| Subword (BPE) | Subwords | Balance | Requires training |\n",
    "| SentencePiece | Subwords | Language agnostic | Requires training |\n",
    "\n",
    "**Code - Text Preprocessing:**\n",
    "```python\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Basic tokenization\n",
    "def simple_tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # remove punctuation\n",
    "    return text.split()\n",
    "\n",
    "# Build vocabulary\n",
    "def build_vocab(texts, min_freq=1):\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        counter.update(simple_tokenize(text))\n",
    "    \n",
    "    vocab = {'<PAD>': 0, '<UNK>': 1, '<BOS>': 2, '<EOS>': 3}\n",
    "    for word, freq in counter.items():\n",
    "        if freq >= min_freq:\n",
    "            vocab[word] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "# Encode text\n",
    "def encode(text, vocab, max_len=None):\n",
    "    tokens = simple_tokenize(text)\n",
    "    ids = [vocab.get(t, vocab['<UNK>']) for t in tokens]\n",
    "    if max_len:\n",
    "        ids = ids[:max_len] + [vocab['<PAD>']] * max(0, max_len - len(ids))\n",
    "    return ids\n",
    "\n",
    "# Using HuggingFace tokenizers\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "encoded = tokenizer(\"Hello world!\", return_tensors='pt')\n",
    "# Returns: input_ids, attention_mask, token_type_ids\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 13.2 Word Embeddings\n",
    "\n",
    "**Q: What are word embeddings and why use them?**\n",
    "\n",
    "Dense vector representations of words that capture semantic meaning.\n",
    "- Similar words have similar vectors\n",
    "- Enable mathematical operations (king - man + woman ≈ queen)\n",
    "- Much smaller than one-hot encoding\n",
    "\n",
    "**Q: Compare Word2Vec, GloVe, and FastText**\n",
    "\n",
    "| Method | Training | Key Feature |\n",
    "|--------|----------|-------------|\n",
    "| Word2Vec (CBOW) | Predict word from context | Fast, local context |\n",
    "| Word2Vec (Skip-gram) | Predict context from word | Better for rare words |\n",
    "| GloVe | Matrix factorization | Global co-occurrence stats |\n",
    "| FastText | Subword n-grams | Handles OOV words |\n",
    "\n",
    "**Code - Word Embeddings:**\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# PyTorch Embedding layer\n",
    "vocab_size = 10000\n",
    "embed_dim = 300\n",
    "embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "\n",
    "# Look up embeddings\n",
    "word_ids = torch.LongTensor([1, 5, 3, 2])\n",
    "word_vectors = embedding(word_ids)  # (4, 300)\n",
    "\n",
    "# Load pretrained embeddings (GloVe)\n",
    "def load_glove(path, vocab, embed_dim):\n",
    "    embeddings = torch.zeros(len(vocab), embed_dim)\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            if word in vocab:\n",
    "                embeddings[vocab[word]] = torch.FloatTensor([float(v) for v in values[1:]])\n",
    "    return embeddings\n",
    "\n",
    "# Using gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "# Train Word2Vec\n",
    "sentences = [[\"hello\", \"world\"], [\"machine\", \"learning\"]]\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1)\n",
    "vector = model.wv[\"hello\"]\n",
    "\n",
    "# Load pretrained\n",
    "glove = KeyedVectors.load_word2vec_format('glove.txt', binary=False)\n",
    "similar = glove.most_similar(\"king\", topn=5)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 13.3 Text Classification\n",
    "\n",
    "**Q: What are common approaches for text classification?**\n",
    "\n",
    "| Approach | Description | When to Use |\n",
    "|----------|-------------|-------------|\n",
    "| Bag of Words + ML | TF-IDF features + classifier | Simple baseline |\n",
    "| CNN | Convolutions over embeddings | Fast, good for short text |\n",
    "| LSTM/GRU | Sequential processing | Captures order |\n",
    "| Transformer | Self-attention | State-of-the-art |\n",
    "\n",
    "**Code - Text Classification Models:**\n",
    "```python\n",
    "# CNN for Text Classification\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes, kernel_sizes=[3,4,5], num_filters=100):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(embed_dim, num_filters, k) for k in kernel_sizes\n",
    "        ])\n",
    "        self.fc = nn.Linear(len(kernel_sizes) * num_filters, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len)\n",
    "        x = self.embedding(x).transpose(1, 2)  # (batch, embed_dim, seq_len)\n",
    "        x = [F.relu(conv(x)) for conv in self.convs]  # list of (batch, num_filters, *)\n",
    "        x = [F.max_pool1d(c, c.size(2)).squeeze(2) for c in x]  # (batch, num_filters) each\n",
    "        x = torch.cat(x, dim=1)  # (batch, num_filters * len(kernel_sizes))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Using HuggingFace for classification\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize\n",
    "inputs = tokenizer(\"This is great!\", return_tensors='pt')\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Part 9: Reinforcement Learning Fundamentals\n",
    "\n",
    "### 2.1 What is Reinforcement Learning?\n",
    "\n",
    "**Q: How does RL differ from supervised/unsupervised learning?**\n",
    "\n",
    "| Paradigm | Data | Feedback | Example |\n",
    "|----------|------|----------|---------|\n",
    "| Supervised | Labeled pairs | Correct answer provided | Image classification |\n",
    "| Unsupervised | Unlabeled | No feedback | Clustering |\n",
    "| Reinforcement | Interaction | Delayed rewards | Game playing |\n",
    "\n",
    "**The RL Loop:**\n",
    "1. Agent observes state\n",
    "2. Agent takes action\n",
    "3. Environment transitions to new state\n",
    "4. Agent receives reward\n",
    "5. Repeat\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2 Core RL Terminology\n",
    "\n",
    "**Q: Define the key RL concepts**\n",
    "\n",
    "- **Agent:** The learner and decision maker\n",
    "- **Environment:** Everything outside the agent\n",
    "- **State (s):** Current situation representation\n",
    "- **Action (a):** Choice the agent can make\n",
    "- **Reward (r):** Immediate feedback signal\n",
    "- **Policy (π):** Strategy mapping states to actions\n",
    "- **Value Function V(s):** Expected return from state s\n",
    "- **Q-Function Q(s,a):** Expected return from taking action a in state s\n",
    "\n",
    "---\n",
    "\n",
    "### 2.3 Markov Decision Process (MDP)\n",
    "\n",
    "**Q: What is an MDP?**\n",
    "\n",
    "An MDP is defined by tuple (S, A, P, R, γ):\n",
    "- **S:** State space\n",
    "- **A:** Action space\n",
    "- **P(s'|s,a):** Transition probability\n",
    "- **R(s,a,s'):** Reward function\n",
    "- **γ:** Discount factor (0 to 1)\n",
    "\n",
    "**The Markov Property:** Future depends only on present, not past.\n",
    "$$P(s_{t+1}|s_t, a_t, s_{t-1}, ...) = P(s_{t+1}|s_t, a_t)$$\n",
    "\n",
    "---\n",
    "\n",
    "### 2.4 Value Functions and Bellman Equations\n",
    "\n",
    "**Q: Explain the Bellman equation**\n",
    "\n",
    "**State-Value Function:**\n",
    "$$V^\\pi(s) = \\mathbb{E}_\\pi[G_t | S_t = s]$$\n",
    "\n",
    "**Action-Value Function:**\n",
    "$$Q^\\pi(s,a) = \\mathbb{E}_\\pi[G_t | S_t = s, A_t = a]$$\n",
    "\n",
    "**Bellman Equation for V:**\n",
    "$$V^\\pi(s) = \\sum_a \\pi(a|s) \\sum_{s'} P(s'|s,a)[R(s,a,s') + \\gamma V^\\pi(s')]$$\n",
    "\n",
    "**Bellman Optimality Equation:**\n",
    "$$V^*(s) = \\max_a \\sum_{s'} P(s'|s,a)[R(s,a,s') + \\gamma V^*(s')]$$\n",
    "\n",
    "---\n",
    "\n",
    "### 2.5 Exploration vs Exploitation\n",
    "\n",
    "**Q: Explain the exploration-exploitation dilemma**\n",
    "\n",
    "- **Exploitation:** Use current best knowledge\n",
    "- **Exploration:** Try new actions to discover better options\n",
    "\n",
    "**Strategies:**\n",
    "| Strategy | Description |\n",
    "|----------|-------------|\n",
    "| ε-greedy | Random action with prob ε |\n",
    "| UCB | Optimism in face of uncertainty |\n",
    "| Softmax/Boltzmann | Sample proportional to Q-values |\n",
    "| Optimistic Init | Start with high values |\n",
    "\n",
    "---\n",
    "\n",
    "### 2.6 Model-Based vs Model-Free RL\n",
    "\n",
    "**Q: Compare model-based and model-free approaches**\n",
    "\n",
    "| Aspect | Model-Based | Model-Free |\n",
    "|--------|-------------|------------|\n",
    "| Requires | P(s'\\|s,a), R | No model |\n",
    "| Sample efficiency | High | Low |\n",
    "| Computation | Planning expensive | Direct learning |\n",
    "| Examples | Dynamic Programming | Q-Learning, Policy Gradient |\n",
    "\n",
    "---\n",
    "\n",
    "### 2.7 Key RL Algorithms\n",
    "\n",
    "**Dynamic Programming (requires model):**\n",
    "- **Policy Iteration:** Evaluate → Improve → Repeat\n",
    "- **Value Iteration:** Combine evaluation and improvement\n",
    "\n",
    "**Monte Carlo (episode-based):**\n",
    "- Learn from complete episodes\n",
    "- Unbiased but high variance\n",
    "- Only for episodic tasks\n",
    "\n",
    "**Temporal Difference (step-based):**\n",
    "- Learn from every step (bootstrap)\n",
    "- Lower variance, some bias\n",
    "- Works for continuing tasks\n",
    "\n",
    "**TD(0) Update:**\n",
    "$$V(S_t) \\leftarrow V(S_t) + \\alpha[R_{t+1} + \\gamma V(S_{t+1}) - V(S_t)]$$\n",
    "\n",
    "---\n",
    "\n",
    "### 2.8 Q-Learning\n",
    "\n",
    "**Q: Explain Q-Learning**\n",
    "\n",
    "Off-policy TD control that learns optimal Q* directly:\n",
    "\n",
    "$$Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha[R_{t+1} + \\gamma \\max_a Q(S_{t+1}, a) - Q(S_t, A_t)]$$\n",
    "\n",
    "**Key properties:**\n",
    "- Off-policy: learns optimal policy while exploring\n",
    "- Model-free: no environment dynamics needed\n",
    "- Uses max over next state actions (vs SARSA which uses actual next action)\n",
    "\n",
    "**SARSA vs Q-Learning:**\n",
    "| Aspect | SARSA | Q-Learning |\n",
    "|--------|-------|------------|\n",
    "| Type | On-policy | Off-policy |\n",
    "| Update | Uses actual A' | Uses max Q |\n",
    "| Behavior | Conservative | Optimistic |\n",
    "\n",
    "**Code - Q-Learning Implementation:**\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def q_learning(env, episodes=1000, alpha=0.1, gamma=0.99, epsilon=0.1):\n",
    "    \"\"\"Tabular Q-Learning algorithm\"\"\"\n",
    "    Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            # Epsilon-greedy action selection\n",
    "            if np.random.random() < epsilon:\n",
    "                action = env.action_space.sample()  # explore\n",
    "            else:\n",
    "                action = np.argmax(Q[state])        # exploit\n",
    "            \n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            # Q-Learning update (off-policy: uses max)\n",
    "            Q[state, action] += alpha * (\n",
    "                reward + gamma * np.max(Q[next_state]) - Q[state, action]\n",
    "            )\n",
    "            state = next_state\n",
    "    \n",
    "    return Q\n",
    "\n",
    "# Epsilon decay schedule\n",
    "def get_epsilon(episode, min_eps=0.01, max_eps=1.0, decay=0.995):\n",
    "    return max(min_eps, max_eps * (decay ** episode))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2.9 Deep Q-Networks (DQN)\n",
    "\n",
    "**Q: What innovations made DQN work?**\n",
    "\n",
    "1. **Experience Replay:**\n",
    "   - Store transitions in buffer\n",
    "   - Sample random mini-batches\n",
    "   - Breaks correlation, improves sample efficiency\n",
    "\n",
    "2. **Target Network:**\n",
    "   - Separate network for TD target\n",
    "   - Updated periodically (not every step)\n",
    "   - Stabilizes training\n",
    "\n",
    "3. **Function Approximation:**\n",
    "   - Neural network approximates Q(s,a)\n",
    "   - Handles high-dimensional states (images)\n",
    "   - Generalizes across similar states\n",
    "\n",
    "**DQN Loss:**\n",
    "$$L(\\theta) = \\mathbb{E}[(r + \\gamma \\max_{a'} Q(s', a'; \\theta^-) - Q(s, a; \\theta))^2]$$\n",
    "\n",
    "**Code - DQN Components:**\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "# Q-Network\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(state_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, action_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Experience Replay Buffer\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity=10000):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        return (torch.FloatTensor(states), torch.LongTensor(actions),\n",
    "                torch.FloatTensor(rewards), torch.FloatTensor(next_states),\n",
    "                torch.FloatTensor(dones))\n",
    "\n",
    "# DQN Training Step\n",
    "def train_dqn(q_net, target_net, buffer, optimizer, batch_size=32, gamma=0.99):\n",
    "    states, actions, rewards, next_states, dones = buffer.sample(batch_size)\n",
    "    \n",
    "    # Current Q values\n",
    "    q_values = q_net(states).gather(1, actions.unsqueeze(1))\n",
    "    \n",
    "    # Target Q values (from target network)\n",
    "    with torch.no_grad():\n",
    "        next_q = target_net(next_states).max(1)[0]\n",
    "        targets = rewards + gamma * next_q * (1 - dones)\n",
    "    \n",
    "    loss = nn.MSELoss()(q_values.squeeze(), targets)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2.10 Policy Gradient Methods\n",
    "\n",
    "**Q: Explain policy gradient vs value-based methods**\n",
    "\n",
    "**Value-Based (Q-Learning, DQN):**\n",
    "- Learn Q(s,a), derive policy from it\n",
    "- Policy is implicit (argmax Q)\n",
    "- Works well for discrete actions\n",
    "\n",
    "**Policy-Based (Policy Gradient):**\n",
    "- Learn policy π(a|s) directly\n",
    "- Can handle continuous actions\n",
    "- Can learn stochastic policies\n",
    "\n",
    "**Policy Gradient Theorem:**\n",
    "$$\\nabla_\\theta J(\\theta) = \\mathbb{E}_\\pi[\\nabla_\\theta \\log \\pi_\\theta(a|s) \\cdot Q^\\pi(s,a)]$$\n",
    "\n",
    "**REINFORCE Algorithm:**\n",
    "$$\\theta \\leftarrow \\theta + \\alpha \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t) \\cdot G_t$$\n",
    "\n",
    "**Code - REINFORCE (Policy Gradient):**\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, action_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.softmax(self.fc2(x), dim=-1)\n",
    "\n",
    "def reinforce(env, policy, optimizer, episodes=1000, gamma=0.99):\n",
    "    for episode in range(episodes):\n",
    "        states, actions, rewards = [], [], []\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        # Collect episode\n",
    "        while not done:\n",
    "            state_t = torch.FloatTensor(state)\n",
    "            probs = policy(state_t)\n",
    "            action = torch.multinomial(probs, 1).item()\n",
    "            \n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            states.append(state_t)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            state = next_state\n",
    "        \n",
    "        # Compute returns (discounted cumulative rewards)\n",
    "        returns = []\n",
    "        G = 0\n",
    "        for r in reversed(rewards):\n",
    "            G = r + gamma * G\n",
    "            returns.insert(0, G)\n",
    "        returns = torch.FloatTensor(returns)\n",
    "        returns = (returns - returns.mean()) / (returns.std() + 1e-8)  # normalize\n",
    "        \n",
    "        # Policy gradient update\n",
    "        optimizer.zero_grad()\n",
    "        for state_t, action, G in zip(states, actions, returns):\n",
    "            probs = policy(state_t)\n",
    "            log_prob = torch.log(probs[action])\n",
    "            loss = -log_prob * G  # negative for gradient ascent\n",
    "            loss.backward()\n",
    "        optimizer.step()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2.11 Actor-Critic Methods\n",
    "\n",
    "**Q: What is Actor-Critic?**\n",
    "\n",
    "Combines policy gradient (actor) with value function (critic):\n",
    "- **Actor:** Policy network π(a|s; θ)\n",
    "- **Critic:** Value network V(s; w) or Q(s,a; w)\n",
    "\n",
    "**Advantage Actor-Critic (A2C):**\n",
    "$$A(s,a) = Q(s,a) - V(s) \\approx r + \\gamma V(s') - V(s)$$\n",
    "\n",
    "Uses advantage instead of return to reduce variance.\n",
    "\n",
    "**Popular Algorithms:**\n",
    "- A2C/A3C: Asynchronous advantage actor-critic\n",
    "- PPO: Proximal Policy Optimization (clipped objective)\n",
    "- SAC: Soft Actor-Critic (entropy regularization)\n",
    "\n",
    "**Code - Actor-Critic:**\n",
    "```python\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super().__init__()\n",
    "        self.shared = nn.Linear(state_dim, 128)\n",
    "        self.actor = nn.Linear(128, action_dim)   # policy head\n",
    "        self.critic = nn.Linear(128, 1)           # value head\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.shared(x))\n",
    "        policy = F.softmax(self.actor(x), dim=-1)\n",
    "        value = self.critic(x)\n",
    "        return policy, value\n",
    "\n",
    "def a2c_update(model, optimizer, states, actions, rewards, next_states, dones, gamma=0.99):\n",
    "    states = torch.FloatTensor(states)\n",
    "    next_states = torch.FloatTensor(next_states)\n",
    "    actions = torch.LongTensor(actions)\n",
    "    rewards = torch.FloatTensor(rewards)\n",
    "    dones = torch.FloatTensor(dones)\n",
    "    \n",
    "    policy, values = model(states)\n",
    "    _, next_values = model(next_states)\n",
    "    \n",
    "    # Advantage = TD error\n",
    "    targets = rewards + gamma * next_values.squeeze() * (1 - dones)\n",
    "    advantages = targets - values.squeeze()\n",
    "    \n",
    "    # Actor loss (policy gradient with advantage)\n",
    "    log_probs = torch.log(policy.gather(1, actions.unsqueeze(1)))\n",
    "    actor_loss = -(log_probs.squeeze() * advantages.detach()).mean()\n",
    "    \n",
    "    # Critic loss (value function)\n",
    "    critic_loss = F.mse_loss(values.squeeze(), targets.detach())\n",
    "    \n",
    "    # Combined loss\n",
    "    loss = actor_loss + 0.5 * critic_loss\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2.12 Common RL Interview Questions\n",
    "\n",
    "1. **Why use discount factor γ?**\n",
    "   - Mathematical: ensures finite returns\n",
    "   - Practical: prefer sooner rewards\n",
    "   - Typical values: 0.9, 0.95, 0.99\n",
    "\n",
    "2. **On-policy vs Off-policy?**\n",
    "   - On-policy: learn about policy being followed (SARSA)\n",
    "   - Off-policy: learn about different policy (Q-Learning)\n",
    "\n",
    "3. **Why does DQN need experience replay?**\n",
    "   - Breaks correlation between consecutive samples\n",
    "   - Improves sample efficiency\n",
    "   - Stabilizes training\n",
    "\n",
    "4. **When to use policy gradient vs Q-learning?**\n",
    "   - Q-learning: discrete actions, sample efficient\n",
    "   - Policy gradient: continuous actions, stochastic policies\n",
    "\n",
    "5. **What is the deadly triad?**\n",
    "   - Function approximation + Bootstrapping + Off-policy\n",
    "   - Can cause instability; DQN addresses with target network\n",
    "\n",
    "---\n",
    "\n",
    "## Part 10: Model Deployment & MLOps\n",
    "\n",
    "### 14.1 Model Optimization\n",
    "\n",
    "**Q: What is quantization?**\n",
    "\n",
    "Reduce model precision to speed up inference and reduce memory:\n",
    "\n",
    "| Type | Description | Speedup |\n",
    "|------|-------------|---------|\n",
    "| FP32 → FP16 | Half precision | 2x |\n",
    "| FP32 → INT8 | 8-bit integers | 4x |\n",
    "| FP32 → INT4 | 4-bit integers | 8x |\n",
    "\n",
    "**Types of quantization:**\n",
    "- **Post-training quantization:** Quantize after training (easy, some accuracy loss)\n",
    "- **Quantization-aware training:** Simulate quantization during training (better accuracy)\n",
    "- **Dynamic quantization:** Quantize weights, compute activations dynamically\n",
    "\n",
    "**Q: What is pruning?**\n",
    "\n",
    "Remove unnecessary weights/neurons:\n",
    "- **Magnitude pruning:** Remove small weights\n",
    "- **Structured pruning:** Remove entire channels/layers\n",
    "- **Lottery ticket hypothesis:** Sparse subnetworks can match full network\n",
    "\n",
    "**Code - Model Optimization:**\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# Dynamic Quantization (easiest)\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "# Static Quantization\n",
    "model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "torch.quantization.prepare(model, inplace=True)\n",
    "# Calibrate with representative data\n",
    "for data in calibration_loader:\n",
    "    model(data)\n",
    "torch.quantization.convert(model, inplace=True)\n",
    "\n",
    "# FP16 inference\n",
    "model.half()\n",
    "with torch.cuda.amp.autocast():\n",
    "    output = model(input.half())\n",
    "\n",
    "# Pruning\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "# Prune 30% of weights in a layer\n",
    "prune.l1_unstructured(model.fc1, name='weight', amount=0.3)\n",
    "\n",
    "# Check sparsity\n",
    "sparsity = 100 * float(torch.sum(model.fc1.weight == 0)) / model.fc1.weight.nelement()\n",
    "\n",
    "# Remove pruning reparametrization (make permanent)\n",
    "prune.remove(model.fc1, 'weight')\n",
    "\n",
    "# Knowledge Distillation\n",
    "def distillation_loss(student_logits, teacher_logits, labels, T=4, alpha=0.7):\n",
    "    soft_loss = F.kl_div(\n",
    "        F.log_softmax(student_logits / T, dim=1),\n",
    "        F.softmax(teacher_logits / T, dim=1),\n",
    "        reduction='batchmean'\n",
    "    ) * (T * T)\n",
    "    hard_loss = F.cross_entropy(student_logits, labels)\n",
    "    return alpha * soft_loss + (1 - alpha) * hard_loss\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 14.2 Model Export and Serving\n",
    "\n",
    "**Q: What is ONNX?**\n",
    "\n",
    "Open Neural Network Exchange - standard format for ML models.\n",
    "- Export from PyTorch, TensorFlow, etc.\n",
    "- Run on various runtimes (ONNX Runtime, TensorRT)\n",
    "- Enables cross-framework deployment\n",
    "\n",
    "**Q: Compare deployment options**\n",
    "\n",
    "| Option | Use Case | Pros | Cons |\n",
    "|--------|----------|------|------|\n",
    "| TorchScript | PyTorch production | Native, easy | PyTorch only |\n",
    "| ONNX | Cross-platform | Portable | Some ops unsupported |\n",
    "| TensorRT | NVIDIA GPUs | Fastest on GPU | NVIDIA only |\n",
    "| TFLite | Mobile/Edge | Small, fast | Limited ops |\n",
    "| Triton | Multi-model serving | Scalable | Complex setup |\n",
    "\n",
    "**Code - Model Export:**\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# TorchScript (tracing)\n",
    "traced_model = torch.jit.trace(model, example_input)\n",
    "traced_model.save(\"model_traced.pt\")\n",
    "\n",
    "# TorchScript (scripting - for control flow)\n",
    "scripted_model = torch.jit.script(model)\n",
    "scripted_model.save(\"model_scripted.pt\")\n",
    "\n",
    "# Load TorchScript model\n",
    "loaded = torch.jit.load(\"model_traced.pt\")\n",
    "output = loaded(input)\n",
    "\n",
    "# Export to ONNX\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    example_input,\n",
    "    \"model.onnx\",\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")\n",
    "\n",
    "# Run with ONNX Runtime\n",
    "import onnxruntime as ort\n",
    "\n",
    "session = ort.InferenceSession(\"model.onnx\")\n",
    "outputs = session.run(None, {\"input\": input_numpy})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 14.3 MLOps Best Practices\n",
    "\n",
    "**Q: What is MLOps?**\n",
    "\n",
    "DevOps practices applied to ML:\n",
    "- Version control for code, data, and models\n",
    "- Automated training pipelines\n",
    "- Model monitoring and retraining\n",
    "- A/B testing and gradual rollout\n",
    "\n",
    "**Q: What should you monitor in production?**\n",
    "\n",
    "| Category | Metrics |\n",
    "|----------|---------|\n",
    "| Model performance | Accuracy, latency, throughput |\n",
    "| Data quality | Missing values, distribution shift |\n",
    "| System health | CPU/GPU usage, memory, errors |\n",
    "| Business metrics | Conversion, engagement |\n",
    "\n",
    "**Q: What is data drift and how do you detect it?**\n",
    "\n",
    "Data drift: Input distribution changes over time.\n",
    "- **Detection:** Statistical tests (KS test, PSI), monitoring feature distributions\n",
    "- **Solutions:** Retrain on new data, online learning, feature engineering\n",
    "\n",
    "**Code - Basic Model Serving (FastAPI):**\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "import torch\n",
    "\n",
    "app = FastAPI()\n",
    "model = torch.jit.load(\"model.pt\")\n",
    "model.eval()\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(data: dict):\n",
    "    input_tensor = torch.tensor(data[\"features\"])\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "    return {\"prediction\": output.tolist()}\n",
    "\n",
    "# Run with: uvicorn app:app --host 0.0.0.0 --port 8000\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Part 11: Distributed Training\n",
    "\n",
    "### 15.1 Parallelism Strategies\n",
    "\n",
    "**Q: Compare data parallelism vs model parallelism**\n",
    "\n",
    "| | Data Parallelism | Model Parallelism |\n",
    "|---|---|---|\n",
    "| Split | Data across GPUs | Model across GPUs |\n",
    "| When | Model fits in GPU | Model too large |\n",
    "| Communication | Gradient sync | Activation passing |\n",
    "| Scaling | Easy | Complex |\n",
    "\n",
    "**Q: What is gradient accumulation?**\n",
    "\n",
    "Simulate larger batch sizes with limited memory:\n",
    "1. Forward/backward on small batch\n",
    "2. Accumulate gradients (don't zero)\n",
    "3. After N steps, update weights\n",
    "\n",
    "Effective batch size = batch_size × accumulation_steps × num_gpus\n",
    "\n",
    "**Q: Explain ZeRO optimization**\n",
    "\n",
    "Zero Redundancy Optimizer (DeepSpeed):\n",
    "- **ZeRO-1:** Partition optimizer states\n",
    "- **ZeRO-2:** + Partition gradients\n",
    "- **ZeRO-3:** + Partition parameters\n",
    "\n",
    "Reduces memory per GPU, enables training larger models.\n",
    "\n",
    "**Code - Distributed Training:**\n",
    "```python\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "# Initialize process group\n",
    "def setup(rank, world_size):\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "# DDP Training\n",
    "def train_ddp(rank, world_size):\n",
    "    setup(rank, world_size)\n",
    "    \n",
    "    model = MyModel().to(rank)\n",
    "    model = DDP(model, device_ids=[rank])\n",
    "    \n",
    "    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)\n",
    "    dataloader = DataLoader(dataset, sampler=sampler, batch_size=32)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        sampler.set_epoch(epoch)  # Important for shuffling\n",
    "        for batch in dataloader:\n",
    "            # Training step\n",
    "            pass\n",
    "    \n",
    "    cleanup()\n",
    "\n",
    "# Launch with torchrun\n",
    "# torchrun --nproc_per_node=4 train.py\n",
    "\n",
    "# Gradient Accumulation\n",
    "accumulation_steps = 4\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for i, batch in enumerate(dataloader):\n",
    "    loss = model(batch) / accumulation_steps\n",
    "    loss.backward()\n",
    "    \n",
    "    if (i + 1) % accumulation_steps == 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "# Mixed Precision Training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for batch in dataloader:\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    with torch.cuda.amp.autocast():\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, target)\n",
    "    \n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Part 12: Debugging ML Models\n",
    "\n",
    "### 16.1 Common Failure Modes\n",
    "\n",
    "**Q: Model not learning (loss not decreasing)**\n",
    "\n",
    "Checklist:\n",
    "1. Learning rate too high/low\n",
    "2. Data loading bug (check labels match inputs)\n",
    "3. Loss function mismatch (e.g., softmax + NLLLoss)\n",
    "4. Gradient issues (vanishing/exploding)\n",
    "5. Model in eval mode during training\n",
    "6. Forgetting optimizer.zero_grad()\n",
    "\n",
    "**Q: Model overfitting**\n",
    "\n",
    "Signs: Training loss ↓, validation loss ↑\n",
    "\n",
    "Solutions:\n",
    "- More data / data augmentation\n",
    "- Regularization (dropout, weight decay)\n",
    "- Simpler model\n",
    "- Early stopping\n",
    "- Batch normalization\n",
    "\n",
    "**Q: Model underfitting**\n",
    "\n",
    "Signs: Both training and validation loss high\n",
    "\n",
    "Solutions:\n",
    "- More complex model\n",
    "- Train longer\n",
    "- Better features\n",
    "- Less regularization\n",
    "- Check for data issues\n",
    "\n",
    "### 16.2 Debugging Techniques\n",
    "\n",
    "**Code - Debugging Tools:**\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# Check for NaN/Inf\n",
    "def check_nan(tensor, name=\"tensor\"):\n",
    "    if torch.isnan(tensor).any():\n",
    "        print(f\"NaN detected in {name}\")\n",
    "    if torch.isinf(tensor).any():\n",
    "        print(f\"Inf detected in {name}\")\n",
    "\n",
    "# Gradient checking\n",
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(f\"{name}: grad_norm={param.grad.norm():.4f}\")\n",
    "        if param.grad.norm() == 0:\n",
    "            print(f\"  WARNING: Zero gradient!\")\n",
    "        if param.grad.norm() > 100:\n",
    "            print(f\"  WARNING: Exploding gradient!\")\n",
    "\n",
    "# Hook to inspect activations\n",
    "activations = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "model.layer1.register_forward_hook(get_activation('layer1'))\n",
    "\n",
    "# Verify data loading\n",
    "for batch_idx, (data, target) in enumerate(dataloader):\n",
    "    print(f\"Batch {batch_idx}: data shape={data.shape}, target shape={target.shape}\")\n",
    "    print(f\"  Data range: [{data.min():.2f}, {data.max():.2f}]\")\n",
    "    print(f\"  Target values: {target.unique().tolist()}\")\n",
    "    if batch_idx >= 2:\n",
    "        break\n",
    "\n",
    "# Overfit on single batch (sanity check)\n",
    "single_batch = next(iter(dataloader))\n",
    "for i in range(100):\n",
    "    loss = train_step(model, single_batch)\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Step {i}: loss={loss:.4f}\")\n",
    "# Loss should go to ~0 if model can learn\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Part 13: ML System Design\n",
    "\n",
    "### 17.1 System Design Framework\n",
    "\n",
    "**Q: How do you approach ML system design questions?**\n",
    "\n",
    "1. **Clarify requirements**\n",
    "   - What's the goal? (metric to optimize)\n",
    "   - Scale? (QPS, data size, latency)\n",
    "   - Constraints? (budget, real-time vs batch)\n",
    "\n",
    "2. **Data pipeline**\n",
    "   - Data sources and collection\n",
    "   - Feature engineering\n",
    "   - Storage (data lake, feature store)\n",
    "\n",
    "3. **Model selection**\n",
    "   - Baseline → simple ML → deep learning\n",
    "   - Online vs offline inference\n",
    "   - Training infrastructure\n",
    "\n",
    "4. **Serving architecture**\n",
    "   - API design\n",
    "   - Caching strategy\n",
    "   - Load balancing\n",
    "\n",
    "5. **Monitoring & iteration**\n",
    "   - Metrics to track\n",
    "   - A/B testing\n",
    "   - Feedback loops\n",
    "\n",
    "### 17.2 Common System Design Problems\n",
    "\n",
    "**Recommendation System:**\n",
    "```\n",
    "User Request → Candidate Generation → Ranking → Re-ranking → Results\n",
    "                    ↓                    ↓\n",
    "              Collaborative         Deep Neural\n",
    "              Filtering             Network\n",
    "              (fast, coarse)        (slow, precise)\n",
    "```\n",
    "\n",
    "**Key components:**\n",
    "- Candidate generation: ANN search, collaborative filtering\n",
    "- Ranking model: Two-tower, cross-attention\n",
    "- Feature store: User history, item embeddings\n",
    "- Real-time signals: Recent clicks, context\n",
    "\n",
    "**Search Ranking:**\n",
    "```\n",
    "Query → Query Understanding → Retrieval → Ranking → Results\n",
    "              ↓                   ↓           ↓\n",
    "         Spell check          BM25/ANN    Learning\n",
    "         Query expansion      Inverted    to Rank\n",
    "         Intent detection     Index       (LTR)\n",
    "```\n",
    "\n",
    "**Fraud Detection:**\n",
    "- Real-time scoring (low latency)\n",
    "- Imbalanced data handling\n",
    "- Feature engineering (velocity, patterns)\n",
    "- Explainability requirements\n",
    "- Feedback delay (labels come late)\n",
    "\n",
    "**Content Moderation:**\n",
    "- Multi-modal (text, image, video)\n",
    "- Multi-label classification\n",
    "- Human-in-the-loop\n",
    "- Edge cases and adversarial content\n",
    "- Latency vs accuracy tradeoff\n",
    "\n",
    "---\n",
    "\n",
    "### 17.3 Scaling Considerations\n",
    "\n",
    "**Q: How do you handle high QPS?**\n",
    "\n",
    "| Strategy | Description |\n",
    "|----------|-------------|\n",
    "| Caching | Cache predictions for common inputs |\n",
    "| Batching | Batch requests for GPU efficiency |\n",
    "| Model distillation | Smaller, faster model |\n",
    "| Quantization | Reduce precision |\n",
    "| Horizontal scaling | More replicas |\n",
    "| Async processing | Queue non-urgent requests |\n",
    "\n",
    "**Q: How do you handle large-scale training data?**\n",
    "\n",
    "- Distributed training (data parallelism)\n",
    "- Data sampling strategies\n",
    "- Online/incremental learning\n",
    "- Feature hashing for high cardinality\n",
    "- Approximate algorithms\n",
    "\n",
    "---\n",
    "\n",
    "## Part 14: Robotics & Embodied AI Fundamentals\n",
    "\n",
    "### 8.1 Robot Perception Pipeline\n",
    "\n",
    "**Q: Describe the perception stack for a humanoid robot**\n",
    "\n",
    "```\n",
    "Sensors → Preprocessing → Feature Extraction → Fusion → State Estimation → Planning\n",
    "```\n",
    "\n",
    "| Sensor | Data Type | Use Case |\n",
    "|--------|-----------|----------|\n",
    "| RGB Camera | Images | Object detection, scene understanding |\n",
    "| Depth Camera | Point clouds | 3D reconstruction, obstacle detection |\n",
    "| LiDAR | Sparse 3D points | Long-range mapping, localization |\n",
    "| IMU | Acceleration, angular velocity | Pose estimation, balance |\n",
    "| Force/Torque | Contact forces | Manipulation, grasping |\n",
    "| Joint Encoders | Position, velocity | Proprioception |\n",
    "\n",
    "**Q: What is sensor fusion?**\n",
    "\n",
    "Combining data from multiple sensors to get more accurate state estimates than any single sensor alone. Methods:\n",
    "- Early fusion: Concatenate raw sensor data\n",
    "- Late fusion: Combine predictions from separate models\n",
    "- Kalman Filter: Optimal fusion for linear Gaussian systems\n",
    "- Extended Kalman Filter (EKF): For nonlinear systems\n",
    "\n",
    "---\n",
    "\n",
    "### 8.2 Coordinate Frames & Transformations\n",
    "\n",
    "**Q: Explain common coordinate frames in robotics**\n",
    "\n",
    "- **World frame:** Fixed global reference\n",
    "- **Body frame:** Attached to robot base\n",
    "- **Camera frame:** Attached to camera sensor\n",
    "- **End-effector frame:** At robot gripper/hand\n",
    "\n",
    "**Q: How do you represent 3D rotations?**\n",
    "\n",
    "| Representation | Pros | Cons |\n",
    "|----------------|------|------|\n",
    "| Euler angles | Intuitive | Gimbal lock |\n",
    "| Rotation matrix | No singularities | 9 params, must be orthogonal |\n",
    "| Quaternion | Compact (4 params), no gimbal lock | Not intuitive |\n",
    "| Axis-angle | Intuitive for small rotations | Singularity at 0° |\n",
    "\n",
    "**Code - Transformations:**\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "# Quaternion to rotation matrix\n",
    "quat = [0, 0, 0.707, 0.707]  # [x, y, z, w]\n",
    "R = Rotation.from_quat(quat).as_matrix()\n",
    "\n",
    "# Euler angles to rotation matrix\n",
    "euler = [0, 0, np.pi/2]  # roll, pitch, yaw\n",
    "R = Rotation.from_euler('xyz', euler).as_matrix()\n",
    "\n",
    "# Homogeneous transformation matrix (4x4)\n",
    "def make_transform(R, t):\n",
    "    \"\"\"Create 4x4 transformation matrix from rotation R and translation t\"\"\"\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = t\n",
    "    return T\n",
    "\n",
    "# Transform a point\n",
    "def transform_point(T, point):\n",
    "    p_homo = np.append(point, 1)  # homogeneous coordinates\n",
    "    return (T @ p_homo)[:3]\n",
    "\n",
    "# Inverse transformation\n",
    "T_inv = np.linalg.inv(T)\n",
    "# Or more efficiently:\n",
    "# R_inv = R.T\n",
    "# t_inv = -R.T @ t\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 8.3 Robot Kinematics\n",
    "\n",
    "**Q: Explain forward vs inverse kinematics**\n",
    "\n",
    "| | Forward Kinematics | Inverse Kinematics |\n",
    "|---|---|---|\n",
    "| Input | Joint angles | End-effector pose |\n",
    "| Output | End-effector pose | Joint angles |\n",
    "| Solution | Unique | Multiple or none |\n",
    "| Difficulty | Easy (chain multiplication) | Hard (nonlinear) |\n",
    "\n",
    "**Q: What is the Jacobian in robotics?**\n",
    "\n",
    "Maps joint velocities to end-effector velocities:\n",
    "$$\\dot{x} = J(q) \\dot{q}$$\n",
    "\n",
    "- Used for velocity control\n",
    "- Singularities occur when det(J) = 0 (robot loses DOF)\n",
    "- Pseudo-inverse for redundant robots: $\\dot{q} = J^+ \\dot{x}$\n",
    "\n",
    "**Code - Simple 2-Link Arm Kinematics:**\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def forward_kinematics_2link(q1, q2, L1, L2):\n",
    "    \"\"\"Forward kinematics for 2-link planar arm\"\"\"\n",
    "    x = L1 * np.cos(q1) + L2 * np.cos(q1 + q2)\n",
    "    y = L1 * np.sin(q1) + L2 * np.sin(q1 + q2)\n",
    "    return np.array([x, y])\n",
    "\n",
    "def jacobian_2link(q1, q2, L1, L2):\n",
    "    \"\"\"Jacobian for 2-link planar arm\"\"\"\n",
    "    J = np.array([\n",
    "        [-L1*np.sin(q1) - L2*np.sin(q1+q2), -L2*np.sin(q1+q2)],\n",
    "        [L1*np.cos(q1) + L2*np.cos(q1+q2), L2*np.cos(q1+q2)]\n",
    "    ])\n",
    "    return J\n",
    "\n",
    "def inverse_kinematics_2link(x, y, L1, L2):\n",
    "    \"\"\"Inverse kinematics for 2-link planar arm (elbow-up solution)\"\"\"\n",
    "    c2 = (x**2 + y**2 - L1**2 - L2**2) / (2 * L1 * L2)\n",
    "    s2 = np.sqrt(1 - c2**2)  # elbow-up\n",
    "    q2 = np.arctan2(s2, c2)\n",
    "    q1 = np.arctan2(y, x) - np.arctan2(L2*s2, L1 + L2*c2)\n",
    "    return q1, q2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 8.4 Motion Planning\n",
    "\n",
    "**Q: Compare motion planning algorithms**\n",
    "\n",
    "| Algorithm | Type | Pros | Cons |\n",
    "|-----------|------|------|------|\n",
    "| A* | Graph search | Optimal, complete | Discretization needed |\n",
    "| RRT | Sampling-based | Works in high-dim | Suboptimal paths |\n",
    "| RRT* | Sampling-based | Asymptotically optimal | Slower than RRT |\n",
    "| PRM | Sampling-based | Good for multi-query | Preprocessing needed |\n",
    "| MPC | Optimization | Handles constraints | Computationally expensive |\n",
    "\n",
    "**Q: What is Model Predictive Control (MPC)?**\n",
    "\n",
    "Optimization-based control that:\n",
    "1. Predicts future states over horizon H\n",
    "2. Optimizes control sequence to minimize cost\n",
    "3. Applies only first control\n",
    "4. Repeats at next timestep (receding horizon)\n",
    "\n",
    "$$\\min_{u_0,...,u_{H-1}} \\sum_{t=0}^{H} c(x_t, u_t) \\quad \\text{s.t.} \\quad x_{t+1} = f(x_t, u_t)$$\n",
    "\n",
    "**Code - Simple RRT:**\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "class RRT:\n",
    "    def __init__(self, start, goal, bounds, obstacle_fn, step_size=0.5):\n",
    "        self.start = np.array(start)\n",
    "        self.goal = np.array(goal)\n",
    "        self.bounds = bounds\n",
    "        self.is_collision = obstacle_fn\n",
    "        self.step_size = step_size\n",
    "        self.nodes = [self.start]\n",
    "        self.parents = {0: None}\n",
    "    \n",
    "    def sample_random(self):\n",
    "        return np.random.uniform(self.bounds[0], self.bounds[1])\n",
    "    \n",
    "    def nearest_node(self, point):\n",
    "        distances = [np.linalg.norm(node - point) for node in self.nodes]\n",
    "        return np.argmin(distances)\n",
    "    \n",
    "    def steer(self, from_node, to_point):\n",
    "        direction = to_point - from_node\n",
    "        distance = np.linalg.norm(direction)\n",
    "        if distance > self.step_size:\n",
    "            direction = direction / distance * self.step_size\n",
    "        return from_node + direction\n",
    "    \n",
    "    def plan(self, max_iter=1000, goal_bias=0.1):\n",
    "        for _ in range(max_iter):\n",
    "            # Sample with goal bias\n",
    "            if np.random.random() < goal_bias:\n",
    "                sample = self.goal\n",
    "            else:\n",
    "                sample = self.sample_random()\n",
    "            \n",
    "            # Find nearest and steer\n",
    "            nearest_idx = self.nearest_node(sample)\n",
    "            new_node = self.steer(self.nodes[nearest_idx], sample)\n",
    "            \n",
    "            # Check collision\n",
    "            if not self.is_collision(new_node):\n",
    "                self.nodes.append(new_node)\n",
    "                self.parents[len(self.nodes)-1] = nearest_idx\n",
    "                \n",
    "                # Check if goal reached\n",
    "                if np.linalg.norm(new_node - self.goal) < self.step_size:\n",
    "                    return self.extract_path(len(self.nodes)-1)\n",
    "        return None\n",
    "    \n",
    "    def extract_path(self, goal_idx):\n",
    "        path = []\n",
    "        idx = goal_idx\n",
    "        while idx is not None:\n",
    "            path.append(self.nodes[idx])\n",
    "            idx = self.parents[idx]\n",
    "        return path[::-1]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 8.5 Control Systems\n",
    "\n",
    "**Q: Explain PID control**\n",
    "\n",
    "$$u(t) = K_p e(t) + K_i \\int e(t)dt + K_d \\frac{de(t)}{dt}$$\n",
    "\n",
    "- **P (Proportional):** Responds to current error\n",
    "- **I (Integral):** Eliminates steady-state error\n",
    "- **D (Derivative):** Dampens oscillations\n",
    "\n",
    "**Q: What is impedance control?**\n",
    "\n",
    "Controls the dynamic relationship between force and motion:\n",
    "$$F = M\\ddot{x} + B\\dot{x} + K(x - x_d)$$\n",
    "\n",
    "Makes robot behave like a mass-spring-damper system. Essential for:\n",
    "- Safe human-robot interaction\n",
    "- Compliant manipulation\n",
    "- Contact tasks\n",
    "\n",
    "**Code - PID Controller:**\n",
    "```python\n",
    "class PIDController:\n",
    "    def __init__(self, Kp, Ki, Kd, dt=0.01):\n",
    "        self.Kp = Kp\n",
    "        self.Ki = Ki\n",
    "        self.Kd = Kd\n",
    "        self.dt = dt\n",
    "        self.integral = 0\n",
    "        self.prev_error = 0\n",
    "    \n",
    "    def compute(self, setpoint, measurement):\n",
    "        error = setpoint - measurement\n",
    "        \n",
    "        # Proportional\n",
    "        P = self.Kp * error\n",
    "        \n",
    "        # Integral (with anti-windup)\n",
    "        self.integral += error * self.dt\n",
    "        self.integral = np.clip(self.integral, -10, 10)\n",
    "        I = self.Ki * self.integral\n",
    "        \n",
    "        # Derivative\n",
    "        derivative = (error - self.prev_error) / self.dt\n",
    "        D = self.Kd * derivative\n",
    "        \n",
    "        self.prev_error = error\n",
    "        return P + I + D\n",
    "    \n",
    "    def reset(self):\n",
    "        self.integral = 0\n",
    "        self.prev_error = 0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 8.6 Vision-Language Models (VLMs)\n",
    "\n",
    "**Q: What is a Vision-Language Model?**\n",
    "\n",
    "A model that jointly understands images and text. Architecture typically:\n",
    "1. Vision encoder (ViT, CLIP) → image embeddings\n",
    "2. Language model (LLM) → text understanding\n",
    "3. Cross-modal fusion → joint reasoning\n",
    "\n",
    "**Key VLMs:**\n",
    "| Model | Architecture | Key Innovation |\n",
    "|-------|--------------|----------------|\n",
    "| CLIP | Dual encoder | Contrastive image-text pretraining |\n",
    "| BLIP-2 | Q-Former bridge | Efficient vision-language alignment |\n",
    "| LLaVA | ViT + LLM | Simple projection, instruction tuning |\n",
    "| GPT-4V | Proprietary | Multimodal GPT |\n",
    "\n",
    "**Q: How does CLIP work?**\n",
    "\n",
    "Contrastive learning on image-text pairs:\n",
    "1. Encode images with vision transformer\n",
    "2. Encode text with text transformer\n",
    "3. Train to maximize similarity of matching pairs, minimize non-matching\n",
    "\n",
    "$$\\mathcal{L} = -\\log \\frac{\\exp(sim(I_i, T_i)/\\tau)}{\\sum_j \\exp(sim(I_i, T_j)/\\tau)}$$\n",
    "\n",
    "**Code - Using CLIP:**\n",
    "```python\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Zero-shot image classification\n",
    "image = load_image(\"robot.jpg\")\n",
    "texts = [\"a photo of a robot\", \"a photo of a car\", \"a photo of a person\"]\n",
    "\n",
    "inputs = processor(text=texts, images=image, return_tensors=\"pt\", padding=True)\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Get similarity scores\n",
    "logits_per_image = outputs.logits_per_image  # image-text similarity\n",
    "probs = logits_per_image.softmax(dim=1)  # probabilities\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 8.7 Vision-Language-Action (VLA) Models\n",
    "\n",
    "**Q: What is a VLA model?**\n",
    "\n",
    "Extends VLMs to output robot actions. Takes:\n",
    "- **Vision:** Camera images (RGB, depth)\n",
    "- **Language:** Task instructions\n",
    "- **Outputs:** Robot actions (joint positions, velocities, or end-effector poses)\n",
    "\n",
    "**Key VLA Models:**\n",
    "| Model | Base | Action Space | Key Feature |\n",
    "|-------|------|--------------|-------------|\n",
    "| RT-1 | EfficientNet + Transformer | Discrete | Large-scale robot data |\n",
    "| RT-2 | PaLM-E / PaLI-X | Discrete tokens | VLM → actions |\n",
    "| Octo | Transformer | Continuous | Open-source, multi-robot |\n",
    "| OpenVLA | Llama 2 + SigLIP | Continuous | 7B params, fine-tunable |\n",
    "\n",
    "**Q: How does RT-2 work?**\n",
    "\n",
    "1. Pretrained VLM (PaLM-E) understands vision + language\n",
    "2. Actions tokenized as text (e.g., \"move arm [0.1, 0.2, 0.3]\")\n",
    "3. VLM generates action tokens autoregressively\n",
    "4. Tokens decoded to continuous actions\n",
    "\n",
    "**Q: What is action chunking?**\n",
    "\n",
    "Predicting multiple future actions at once instead of one at a time:\n",
    "- Reduces compounding errors\n",
    "- Smoother trajectories\n",
    "- Used in ACT, Diffusion Policy\n",
    "\n",
    "---\n",
    "\n",
    "### 8.8 Imitation Learning\n",
    "\n",
    "**Q: Compare imitation learning approaches**\n",
    "\n",
    "| Method | Description | Pros | Cons |\n",
    "|--------|-------------|------|------|\n",
    "| Behavior Cloning | Supervised learning on demos | Simple | Compounding errors |\n",
    "| DAgger | Iterative with expert queries | Handles distribution shift | Needs expert access |\n",
    "| IRL | Learn reward, then RL | Generalizes better | Computationally expensive |\n",
    "| GAIL | GAN-style imitation | No reward engineering | Training instability |\n",
    "\n",
    "**Q: What is the distribution shift problem?**\n",
    "\n",
    "In behavior cloning, small errors accumulate because:\n",
    "- Training: states from expert distribution\n",
    "- Testing: states from learned policy (different distribution)\n",
    "- Model never saw recovery from mistakes\n",
    "\n",
    "Solutions: DAgger, action chunking, diffusion policies\n",
    "\n",
    "**Code - Behavior Cloning:**\n",
    "```python\n",
    "class BehaviorCloning(nn.Module):\n",
    "    def __init__(self, obs_dim, action_dim, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, action_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, obs):\n",
    "        return self.net(obs)\n",
    "\n",
    "# Training\n",
    "def train_bc(model, expert_data, epochs=100):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for obs, action in expert_data:\n",
    "            pred_action = model(obs)\n",
    "            loss = F.mse_loss(pred_action, action)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 8.9 Diffusion Policy\n",
    "\n",
    "**Q: What is Diffusion Policy?**\n",
    "\n",
    "Uses diffusion models to generate robot actions:\n",
    "1. Start with noise\n",
    "2. Iteratively denoise to get action sequence\n",
    "3. Captures multimodal action distributions\n",
    "\n",
    "**Advantages:**\n",
    "- Handles multimodal demonstrations (multiple ways to do task)\n",
    "- Generates smooth action sequences\n",
    "- State-of-the-art on many manipulation tasks\n",
    "\n",
    "**Q: How does it differ from standard BC?**\n",
    "\n",
    "| Aspect | Behavior Cloning | Diffusion Policy |\n",
    "|--------|------------------|------------------|\n",
    "| Output | Single action | Action distribution |\n",
    "| Multimodality | Averages modes | Captures all modes |\n",
    "| Generation | Single forward pass | Iterative denoising |\n",
    "| Training | MSE loss | Denoising score matching |\n",
    "\n",
    "**Code - Simplified Diffusion Policy Concept:**\n",
    "```python\n",
    "class DiffusionPolicy(nn.Module):\n",
    "    def __init__(self, obs_dim, action_dim, horizon=16):\n",
    "        super().__init__()\n",
    "        self.horizon = horizon\n",
    "        self.action_dim = action_dim\n",
    "        \n",
    "        # Noise prediction network (simplified)\n",
    "        self.noise_pred = nn.Sequential(\n",
    "            nn.Linear(obs_dim + action_dim * horizon + 1, 256),  # +1 for timestep\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, action_dim * horizon)\n",
    "        )\n",
    "    \n",
    "    def forward(self, obs, noisy_actions, timestep):\n",
    "        \"\"\"Predict noise given observation, noisy actions, and diffusion timestep\"\"\"\n",
    "        t_embed = timestep.float().unsqueeze(-1) / 1000  # simple timestep embedding\n",
    "        x = torch.cat([obs, noisy_actions.flatten(-2), t_embed], dim=-1)\n",
    "        return self.noise_pred(x).view(-1, self.horizon, self.action_dim)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def sample(self, obs, num_steps=50):\n",
    "        \"\"\"Generate actions via iterative denoising\"\"\"\n",
    "        device = obs.device\n",
    "        actions = torch.randn(obs.shape[0], self.horizon, self.action_dim, device=device)\n",
    "        \n",
    "        for t in reversed(range(num_steps)):\n",
    "            timestep = torch.full((obs.shape[0],), t, device=device)\n",
    "            noise_pred = self(obs, actions, timestep)\n",
    "            # Simplified DDPM update (actual implementation more complex)\n",
    "            actions = actions - noise_pred * (1.0 / num_steps)\n",
    "        \n",
    "        return actions\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 8.10 Sim-to-Real Transfer\n",
    "\n",
    "**Q: Why is sim-to-real transfer important?**\n",
    "\n",
    "- Training in simulation is cheap, safe, and parallelizable\n",
    "- Real robot data is expensive and slow to collect\n",
    "- Challenge: simulation doesn't perfectly match reality (reality gap)\n",
    "\n",
    "**Q: Techniques for sim-to-real transfer**\n",
    "\n",
    "| Technique | Description |\n",
    "|-----------|-------------|\n",
    "| Domain Randomization | Randomize sim parameters (friction, mass, lighting) |\n",
    "| System Identification | Measure real parameters, match in sim |\n",
    "| Domain Adaptation | Learn to map sim → real features |\n",
    "| Real-world fine-tuning | Pre-train in sim, fine-tune on real |\n",
    "\n",
    "**Q: What is domain randomization?**\n",
    "\n",
    "Randomize simulation parameters during training so policy becomes robust to variations:\n",
    "- Physics: friction, mass, damping\n",
    "- Visual: lighting, textures, camera pose\n",
    "- Dynamics: delays, noise\n",
    "\n",
    "**Code - Domain Randomization Example:**\n",
    "```python\n",
    "class DomainRandomizer:\n",
    "    def __init__(self):\n",
    "        self.friction_range = (0.5, 1.5)\n",
    "        self.mass_scale_range = (0.8, 1.2)\n",
    "        self.observation_noise = 0.01\n",
    "        self.action_delay_range = (0, 3)  # frames\n",
    "    \n",
    "    def randomize_physics(self, env):\n",
    "        friction = np.random.uniform(*self.friction_range)\n",
    "        mass_scale = np.random.uniform(*self.mass_scale_range)\n",
    "        env.set_friction(friction)\n",
    "        env.scale_masses(mass_scale)\n",
    "    \n",
    "    def add_observation_noise(self, obs):\n",
    "        noise = np.random.normal(0, self.observation_noise, obs.shape)\n",
    "        return obs + noise\n",
    "    \n",
    "    def randomize_action_delay(self):\n",
    "        return np.random.randint(*self.action_delay_range)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 8.11 Recent Advanced Robotics Models\n",
    "\n",
    "#### ACT (Action Chunking with Transformers)\n",
    "\n",
    "**Q: What is ACT?**\n",
    "\n",
    "A transformer-based imitation learning algorithm from Stanford that predicts sequences of actions (\"action chunks\") rather than single actions.\n",
    "\n",
    "**Key Features:**\n",
    "- Uses CVAE (Conditional VAE) to handle multimodal demonstrations\n",
    "- Predicts chunks of 50-100 future actions at once\n",
    "- Achieves 80-90% success on bimanual tasks with only 10 min of demos\n",
    "- Used with ALOHA hardware for low-cost bimanual manipulation\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Observation (images + proprioception) → Encoder → Transformer → Action Chunk (k actions)\n",
    "                                          ↑\n",
    "                                    CVAE latent z (captures style variation)\n",
    "```\n",
    "\n",
    "**Why action chunking helps:**\n",
    "- Reduces compounding errors (fewer decision points)\n",
    "- Captures temporal correlations in demonstrations\n",
    "- Smoother, more natural trajectories\n",
    "\n",
    "**Code - ACT Concept:**\n",
    "```python\n",
    "class ACT(nn.Module):\n",
    "    def __init__(self, obs_dim, action_dim, chunk_size=50, latent_dim=32):\n",
    "        super().__init__()\n",
    "        self.chunk_size = chunk_size\n",
    "        \n",
    "        # CVAE encoder (only used during training)\n",
    "        self.encoder = nn.TransformerEncoder(...)\n",
    "        self.latent_proj = nn.Linear(hidden_dim, latent_dim * 2)  # mean, logvar\n",
    "        \n",
    "        # Decoder (transformer)\n",
    "        self.decoder = nn.TransformerDecoder(...)\n",
    "        self.action_head = nn.Linear(hidden_dim, action_dim)\n",
    "        \n",
    "        # Observation encoder\n",
    "        self.obs_encoder = nn.Sequential(\n",
    "            nn.Linear(obs_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, hidden_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, obs, actions=None):\n",
    "        obs_embed = self.obs_encoder(obs)\n",
    "        \n",
    "        if self.training and actions is not None:\n",
    "            # Encode actions to get latent z (CVAE)\n",
    "            z_mean, z_logvar = self.latent_proj(self.encoder(actions)).chunk(2, dim=-1)\n",
    "            z = z_mean + torch.randn_like(z_logvar) * torch.exp(0.5 * z_logvar)\n",
    "        else:\n",
    "            # At inference, sample z from prior (zero mean, unit var)\n",
    "            z = torch.zeros(obs.shape[0], self.latent_dim, device=obs.device)\n",
    "        \n",
    "        # Decode action chunk\n",
    "        action_chunk = self.decoder(z, obs_embed)\n",
    "        return self.action_head(action_chunk)  # (batch, chunk_size, action_dim)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ALOHA / Mobile ALOHA\n",
    "\n",
    "**Q: What is ALOHA?**\n",
    "\n",
    "A Low-cost Open-source Hardware for bimanual teleoperation and imitation learning.\n",
    "\n",
    "| Version | Features |\n",
    "|---------|----------|\n",
    "| ALOHA | Dual-arm tabletop, ~$20K hardware |\n",
    "| ALOHA 2 | Improved ergonomics, better teleoperation |\n",
    "| Mobile ALOHA | Adds mobile base for whole-body control |\n",
    "| ALOHA Unleashed | DeepMind's diffusion policy on ALOHA 2 |\n",
    "\n",
    "**Key capabilities:**\n",
    "- Bimanual manipulation (two 6-DOF arms)\n",
    "- Leader-follower teleoperation for data collection\n",
    "- Tasks: tying shoelaces, folding clothes, cooking\n",
    "\n",
    "---\n",
    "\n",
    "#### π₀ (Pi-Zero) - Physical Intelligence\n",
    "\n",
    "**Q: What is π₀?**\n",
    "\n",
    "A general-purpose robot foundation model from Physical Intelligence that combines VLM pre-training with flow matching for action generation.\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Vision (images) → PaliGemma VLM (3B) → Flow Matching → Robot Actions\n",
    "Language (task)  ↗                      (iterative denoising)\n",
    "```\n",
    "\n",
    "**Key Innovations:**\n",
    "- Built on PaliGemma (3B parameter VLM)\n",
    "- Uses flow matching instead of diffusion for action generation\n",
    "- Trained on diverse robot data across multiple embodiments\n",
    "- Can fold laundry, clear tables, manipulate deformable objects\n",
    "\n",
    "**Flow Matching vs Diffusion:**\n",
    "| Aspect | Diffusion | Flow Matching |\n",
    "|--------|-----------|---------------|\n",
    "| Process | Add/remove noise | Learn velocity field |\n",
    "| Training | Predict noise | Predict flow direction |\n",
    "| Sampling | Many steps (50-1000) | Fewer steps (10-50) |\n",
    "| Speed | Slower | Faster |\n",
    "\n",
    "---\n",
    "\n",
    "#### NVIDIA GR00T (Generalist Robot 00 Technology)\n",
    "\n",
    "**Q: What is Project GR00T?**\n",
    "\n",
    "NVIDIA's foundation model initiative for humanoid robots, announced at GTC 2024.\n",
    "\n",
    "**Key Features:**\n",
    "- Multimodal: processes language, vision, and outputs actions\n",
    "- Learns from human demonstrations via video\n",
    "- Integrated with NVIDIA Isaac for simulation and RL\n",
    "- Designed for humanoid robots (partnered with Figure, 1X, etc.)\n",
    "\n",
    "**Architecture (High-level):**\n",
    "```\n",
    "Multimodal Input → Foundation Model → High-level Planning\n",
    "(language, video)                            ↓\n",
    "                                    Low-level Control (Isaac)\n",
    "                                            ↓\n",
    "                                      Robot Actions\n",
    "```\n",
    "\n",
    "**Ecosystem:**\n",
    "- Isaac Lab: RL training in simulation\n",
    "- Isaac Sim: High-fidelity physics simulation\n",
    "- Jetson Thor: Edge compute for humanoids\n",
    "\n",
    "---\n",
    "\n",
    "#### OpenVLA\n",
    "\n",
    "**Q: What is OpenVLA?**\n",
    "\n",
    "An open-source 7B parameter Vision-Language-Action model for robot control.\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Image → DINOv2 + SigLIP → Projector → Llama 2 (7B) → Action Tokens\n",
    "                                  ↑\n",
    "                            Language instruction\n",
    "```\n",
    "\n",
    "**Key Details:**\n",
    "- Base: Llama 2 7B language model\n",
    "- Vision: Fused DINOv2 + SigLIP features\n",
    "- Training: 970K trajectories from Open X-Embodiment\n",
    "- Actions: Discretized into 256 bins, output as tokens\n",
    "\n",
    "**Code - OpenVLA-style Action Tokenization:**\n",
    "```python\n",
    "def tokenize_actions(actions, num_bins=256, action_min=-1, action_max=1):\n",
    "    \"\"\"Discretize continuous actions into tokens\"\"\"\n",
    "    # Normalize to [0, 1]\n",
    "    normalized = (actions - action_min) / (action_max - action_min)\n",
    "    # Discretize to bins\n",
    "    tokens = (normalized * (num_bins - 1)).long()\n",
    "    return tokens.clamp(0, num_bins - 1)\n",
    "\n",
    "def detokenize_actions(tokens, num_bins=256, action_min=-1, action_max=1):\n",
    "    \"\"\"Convert tokens back to continuous actions\"\"\"\n",
    "    normalized = tokens.float() / (num_bins - 1)\n",
    "    actions = normalized * (action_max - action_min) + action_min\n",
    "    return actions\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Octo\n",
    "\n",
    "**Q: What is Octo?**\n",
    "\n",
    "An open-source generalist robot policy from UC Berkeley, trained on 800K+ trajectories.\n",
    "\n",
    "**Key Features:**\n",
    "- Transformer-based architecture (27M or 93M params)\n",
    "- Trained on Open X-Embodiment dataset\n",
    "- Supports multiple robots and observation types\n",
    "- Designed for easy fine-tuning to new setups\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Observations → Tokenizers → Transformer Backbone → Readout Heads → Actions\n",
    "(images, lang)   (modular)      (shared)            (task-specific)\n",
    "```\n",
    "\n",
    "**Comparison with OpenVLA:**\n",
    "| Aspect | Octo | OpenVLA |\n",
    "|--------|------|---------|\n",
    "| Size | 27M-93M | 7B |\n",
    "| Base | Custom transformer | Llama 2 |\n",
    "| Actions | Continuous | Discretized tokens |\n",
    "| Focus | Efficiency, fine-tuning | Generalization |\n",
    "\n",
    "---\n",
    "\n",
    "#### FastSAC / FastTD3\n",
    "\n",
    "**Q: What is FastSAC?**\n",
    "\n",
    "An optimized off-policy RL algorithm that enables training humanoid locomotion in 15 minutes on a single GPU.\n",
    "\n",
    "**Key Innovations:**\n",
    "- Optimized SAC/TD3 for massively parallel simulation\n",
    "- Strong domain randomization (dynamics, terrain, perturbations)\n",
    "- Achieves sim-to-real transfer for humanoid walking\n",
    "- Single RTX 4090 GPU, 15 minutes training\n",
    "\n",
    "**Why it matters for humanoids:**\n",
    "- Traditional RL: days of training\n",
    "- PPO (on-policy): hours with parallel sim\n",
    "- FastSAC (off-policy): 15 minutes with better sample efficiency\n",
    "\n",
    "**Code - FastSAC Key Ideas:**\n",
    "```python\n",
    "class FastSAC:\n",
    "    \"\"\"Key optimizations for fast humanoid RL\"\"\"\n",
    "    def __init__(self, env, num_envs=4096):\n",
    "        self.num_envs = num_envs  # Massively parallel\n",
    "        \n",
    "        # Larger replay buffer for off-policy\n",
    "        self.buffer_size = 1_000_000\n",
    "        \n",
    "        # Aggressive domain randomization\n",
    "        self.domain_rand = {\n",
    "            'friction': (0.5, 2.0),\n",
    "            'mass_scale': (0.8, 1.2),\n",
    "            'motor_strength': (0.8, 1.2),\n",
    "            'terrain_roughness': (0, 0.1),\n",
    "            'push_force': (0, 200),  # N\n",
    "        }\n",
    "    \n",
    "    def update(self, batch_size=256):\n",
    "        # Standard SAC update but with:\n",
    "        # 1. Large batch sizes (256-1024)\n",
    "        # 2. High UTD ratio (updates per env step)\n",
    "        # 3. Parallel critic updates\n",
    "        pass\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### RT-1 / RT-2 / RT-X\n",
    "\n",
    "**Q: Compare Google's RT model family**\n",
    "\n",
    "| Model | Architecture | Actions | Key Innovation |\n",
    "|-------|--------------|---------|----------------|\n",
    "| RT-1 | EfficientNet + Transformer | Discrete (256 bins) | Large-scale robot data |\n",
    "| RT-2 | PaLM-E / PaLI-X VLM | Text tokens | VLM → robot actions |\n",
    "| RT-X | RT-2 + cross-embodiment | Text tokens | Transfer across robots |\n",
    "\n",
    "**RT-2 Key Insight:**\n",
    "Actions can be represented as text tokens, allowing VLMs to directly output robot commands:\n",
    "```\n",
    "Input: \"Pick up the apple\" + image\n",
    "Output: \"1 128 64 32 255 128 64\"  (tokenized action)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 8.12 Humanoid Robot Specific Concepts\n",
    "\n",
    "**Q: What makes humanoid control challenging?**\n",
    "\n",
    "- High DOF (30+ joints for Optimus)\n",
    "- Underactuated (can't directly control CoM)\n",
    "- Balance constraints (ZMP, CoP)\n",
    "- Contact dynamics (walking, manipulation)\n",
    "\n",
    "**Q: Explain Zero Moment Point (ZMP)**\n",
    "\n",
    "Point where total moment of inertial and gravity forces is zero. For stable walking:\n",
    "- ZMP must stay within support polygon (foot contact area)\n",
    "- If ZMP exits support polygon → robot falls\n",
    "\n",
    "**Q: What is whole-body control?**\n",
    "\n",
    "Coordinating all joints to achieve multiple objectives:\n",
    "1. Primary: End-effector task (reach object)\n",
    "2. Secondary: Maintain balance\n",
    "3. Tertiary: Joint limit avoidance\n",
    "\n",
    "Uses null-space projection to satisfy lower-priority tasks without affecting higher-priority ones.\n",
    "\n",
    "---\n",
    "\n",
    "### 8.13 Common Robotics Interview Questions\n",
    "\n",
    "1. **How would you approach teaching a robot to pick up novel objects?**\n",
    "   - Use VLA model pretrained on diverse objects (OpenVLA, RT-2)\n",
    "   - Fine-tune with few demonstrations of new objects\n",
    "   - Domain randomization for visual variations\n",
    "\n",
    "2. **How do you handle real-time constraints?**\n",
    "   - Model optimization (quantization, pruning)\n",
    "   - Efficient architectures (MobileNet, EfficientNet)\n",
    "   - Action chunking (predict multiple steps, execute while computing next)\n",
    "   - Hierarchical control (high-level policy at 10Hz, low-level at 1kHz)\n",
    "\n",
    "3. **How would you make a robot safe around humans?**\n",
    "   - Impedance/compliance control\n",
    "   - Force/torque sensing and limits\n",
    "   - Predictive models for human motion\n",
    "   - Fail-safe behaviors\n",
    "\n",
    "4. **What's your approach to debugging a robot that fails in the real world but works in simulation?**\n",
    "   - Check sensor calibration\n",
    "   - Compare state distributions (sim vs real)\n",
    "   - Add domain randomization\n",
    "   - Collect failure cases, add to training\n",
    "\n",
    "5. **How do you handle multimodal inputs (vision + proprioception + language)?**\n",
    "   - Separate encoders for each modality\n",
    "   - Cross-attention or concatenation for fusion\n",
    "   - Pretrained encoders (CLIP for vision, LLM for language)\n",
    "\n",
    "6. **Compare ACT vs Diffusion Policy for imitation learning**\n",
    "   - ACT: CVAE + action chunking, faster inference, good for bimanual\n",
    "   - Diffusion: Better multimodality, smoother trajectories, slower\n",
    "   - Both use action chunking to reduce compounding errors\n",
    "\n",
    "7. **Why would you choose π₀ over OpenVLA?**\n",
    "   - π₀: Flow matching (faster), better for dexterous manipulation\n",
    "   - OpenVLA: Open-source, easier to fine-tune, larger community\n",
    "   - Both: VLM-based, language-conditioned\n",
    "\n",
    "8. **How does FastSAC achieve 15-minute humanoid training?**\n",
    "   - Off-policy (better sample efficiency than PPO)\n",
    "   - Massively parallel simulation (4096+ envs)\n",
    "   - Optimized implementation for GPU\n",
    "   - Strong domain randomization for sim-to-real\n",
    "\n",
    "9. **What are the tradeoffs between discrete vs continuous action spaces in VLAs?**\n",
    "   - Discrete (RT-2, OpenVLA): Leverages LLM tokenization, but loses precision\n",
    "   - Continuous (Octo, π₀): More precise, but needs different output heads\n",
    "   - Hybrid: Coarse discrete + fine continuous refinement\n",
    "\n",
    "10. **How would you deploy a VLA model on a real robot with latency constraints?**\n",
    "    - Action chunking (compute once, execute many)\n",
    "    - Model distillation to smaller network\n",
    "    - Quantization (INT8)\n",
    "    - Async inference pipeline\n",
    "\n",
    "---\n",
    "\n",
    "## Part 15: Data Augmentation\n",
    "\n",
    "### 18.1 Image Augmentation\n",
    "\n",
    "**Q: What augmentations are commonly used for images?**\n",
    "\n",
    "| Augmentation | Effect | When to Use |\n",
    "|--------------|--------|-------------|\n",
    "| Random crop | Translation invariance | Almost always |\n",
    "| Horizontal flip | Mirror invariance | When symmetric |\n",
    "| Color jitter | Lighting robustness | Natural images |\n",
    "| Rotation | Rotation invariance | When applicable |\n",
    "| Cutout/RandomErasing | Occlusion robustness | Classification |\n",
    "| MixUp | Smoother decision boundary | Classification |\n",
    "| CutMix | Combines cutout + mixup | Classification |\n",
    "\n",
    "**Code - Image Augmentation:**\n",
    "```python\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import autoaugment\n",
    "\n",
    "# Standard augmentation pipeline\n",
    "train_transform = T.Compose([\n",
    "    T.RandomResizedCrop(224),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    T.RandomErasing(p=0.5)\n",
    "])\n",
    "\n",
    "# AutoAugment (learned augmentation policy)\n",
    "auto_aug = T.Compose([\n",
    "    T.RandomResizedCrop(224),\n",
    "    autoaugment.AutoAugment(autoaugment.AutoAugmentPolicy.IMAGENET),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# MixUp implementation\n",
    "def mixup(x, y, alpha=0.2):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size)\n",
    "    \n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# MixUp loss\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 18.2 Text Augmentation\n",
    "\n",
    "**Q: What augmentations work for text?**\n",
    "\n",
    "| Technique | Description |\n",
    "|-----------|-------------|\n",
    "| Synonym replacement | Replace words with synonyms |\n",
    "| Random insertion | Insert random synonyms |\n",
    "| Random swap | Swap word positions |\n",
    "| Random deletion | Delete random words |\n",
    "| Back-translation | Translate to another language and back |\n",
    "| EDA | Easy Data Augmentation (combines above) |\n",
    "\n",
    "**Code - Text Augmentation:**\n",
    "```python\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def synonym_replacement(words, n=1):\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([w for w in words if wordnet.synsets(w)]))\n",
    "    random.shuffle(random_word_list)\n",
    "    \n",
    "    for random_word in random_word_list[:n]:\n",
    "        synonyms = []\n",
    "        for syn in wordnet.synsets(random_word):\n",
    "            for lemma in syn.lemmas():\n",
    "                synonyms.append(lemma.name())\n",
    "        if synonyms:\n",
    "            synonym = random.choice(synonyms)\n",
    "            new_words = [synonym if w == random_word else w for w in new_words]\n",
    "    return new_words\n",
    "\n",
    "def random_deletion(words, p=0.1):\n",
    "    if len(words) == 1:\n",
    "        return words\n",
    "    return [w for w in words if random.random() > p] or [random.choice(words)]\n",
    "\n",
    "def random_swap(words, n=1):\n",
    "    new_words = words.copy()\n",
    "    for _ in range(n):\n",
    "        if len(new_words) >= 2:\n",
    "            idx1, idx2 = random.sample(range(len(new_words)), 2)\n",
    "            new_words[idx1], new_words[idx2] = new_words[idx2], new_words[idx1]\n",
    "    return new_words\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 18.3 Tabular Data Augmentation\n",
    "\n",
    "**Q: How do you augment tabular data?**\n",
    "\n",
    "| Technique | Description |\n",
    "|-----------|-------------|\n",
    "| SMOTE | Synthetic minority oversampling |\n",
    "| Noise injection | Add Gaussian noise to features |\n",
    "| Feature crossover | Combine features from different samples |\n",
    "| Mixup | Interpolate between samples |\n",
    "\n",
    "**Code - Tabular Augmentation:**\n",
    "```python\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# SMOTE for imbalanced data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Gaussian noise injection\n",
    "def add_noise(X, noise_factor=0.1):\n",
    "    noise = np.random.normal(0, noise_factor, X.shape)\n",
    "    return X + noise\n",
    "\n",
    "# Feature-wise mixup for tabular\n",
    "def tabular_mixup(X, y, alpha=0.2):\n",
    "    lam = np.random.beta(alpha, alpha, size=(len(X), 1))\n",
    "    index = np.random.permutation(len(X))\n",
    "    X_mixed = lam * X + (1 - lam) * X[index]\n",
    "    y_mixed = lam.squeeze() * y + (1 - lam.squeeze()) * y[index]\n",
    "    return X_mixed, y_mixed\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Part 16: Ethics & Fairness in ML\n",
    "\n",
    "### 19.1 Bias in ML Systems\n",
    "\n",
    "**Q: What types of bias exist in ML?**\n",
    "\n",
    "| Bias Type | Description | Example |\n",
    "|-----------|-------------|---------|\n",
    "| Selection bias | Training data not representative | Hiring model trained on past (biased) decisions |\n",
    "| Measurement bias | Features measured differently | Different quality cameras for different groups |\n",
    "| Algorithmic bias | Model amplifies existing bias | Word embeddings encoding stereotypes |\n",
    "| Evaluation bias | Test set not representative | Face recognition tested mainly on one demographic |\n",
    "\n",
    "### 19.2 Fairness Metrics\n",
    "\n",
    "**Q: What fairness metrics should you consider?**\n",
    "\n",
    "| Metric | Definition | Use When |\n",
    "|--------|------------|----------|\n",
    "| Demographic parity | P(Ŷ=1\\|A=0) = P(Ŷ=1\\|A=1) | Equal positive rates |\n",
    "| Equalized odds | TPR and FPR equal across groups | Equal error rates |\n",
    "| Calibration | P(Y=1\\|Ŷ=p) = p for all groups | Probability estimates |\n",
    "| Individual fairness | Similar individuals treated similarly | Case-by-case fairness |\n",
    "\n",
    "**Q: How do you mitigate bias?**\n",
    "\n",
    "| Stage | Technique |\n",
    "|-------|-----------|\n",
    "| Pre-processing | Resampling, reweighting data |\n",
    "| In-processing | Fairness constraints in loss |\n",
    "| Post-processing | Adjust thresholds per group |\n",
    "\n",
    "**Code - Fairness Evaluation:**\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def demographic_parity(y_pred, sensitive_attr):\n",
    "    \"\"\"Check if positive prediction rate is equal across groups\"\"\"\n",
    "    groups = np.unique(sensitive_attr)\n",
    "    rates = {}\n",
    "    for g in groups:\n",
    "        mask = sensitive_attr == g\n",
    "        rates[g] = y_pred[mask].mean()\n",
    "    return rates\n",
    "\n",
    "def equalized_odds(y_true, y_pred, sensitive_attr):\n",
    "    \"\"\"Check if TPR and FPR are equal across groups\"\"\"\n",
    "    groups = np.unique(sensitive_attr)\n",
    "    metrics = {}\n",
    "    for g in groups:\n",
    "        mask = sensitive_attr == g\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true[mask], y_pred[mask]).ravel()\n",
    "        metrics[g] = {\n",
    "            'tpr': tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "            'fpr': fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        }\n",
    "    return metrics\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 19.3 Responsible AI Practices\n",
    "\n",
    "**Q: What are key responsible AI principles?**\n",
    "\n",
    "1. **Transparency:** Explain how models make decisions\n",
    "2. **Accountability:** Clear ownership of model outcomes\n",
    "3. **Privacy:** Protect user data, differential privacy\n",
    "4. **Safety:** Test for harmful outputs, red-teaming\n",
    "5. **Human oversight:** Human-in-the-loop for high-stakes decisions\n",
    "\n",
    "**Q: What is model interpretability?**\n",
    "\n",
    "| Method | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| LIME | Local | Approximate model locally with interpretable model |\n",
    "| SHAP | Local/Global | Shapley values for feature importance |\n",
    "| Attention weights | Model-specific | Visualize what model attends to |\n",
    "| Integrated gradients | Gradient-based | Attribution to input features |\n",
    "| Counterfactuals | Example-based | \"What would change the prediction?\" |\n",
    "\n",
    "---\n",
    "\n",
    "## Part 17: Common Interview Questions\n",
    "\n",
    "### Conceptual Questions\n",
    "\n",
    "1. **Why do we need non-linear activation functions?**\n",
    "   - Without them, any depth of linear layers collapses to one linear transformation\n",
    "\n",
    "2. **What is the vanishing gradient problem?**\n",
    "   - Gradients become tiny in deep networks, preventing learning. Solutions: ReLU, residual connections, proper initialization\n",
    "\n",
    "3. **Why do transformers use residual connections?**\n",
    "   - Provide \"gradient highways\" for stable training of deep networks\n",
    "\n",
    "4. **What is teacher forcing?**\n",
    "   - During training, feed ground truth tokens to decoder instead of predictions. Faster training but can cause exposure bias.\n",
    "\n",
    "5. **What is the difference between encoder and decoder?**\n",
    "   - Encoder: bidirectional attention, understands input\n",
    "   - Decoder: causal attention, generates output\n",
    "\n",
    "### Practical Questions\n",
    "\n",
    "1. **Your model isn't learning. What do you check?**\n",
    "   - Learning rate (too high/low?)\n",
    "   - Gradient flow (vanishing/exploding?)\n",
    "   - Data pipeline (correct labels?)\n",
    "   - Loss function (appropriate for task?)\n",
    "\n",
    "2. **How do you handle variable-length sequences?**\n",
    "   - Padding + attention mask\n",
    "   - Pack sequences\n",
    "   - Bucket by length\n",
    "\n",
    "3. **How do you reduce memory usage during training?**\n",
    "   - Gradient checkpointing\n",
    "   - Mixed precision (FP16)\n",
    "   - Gradient accumulation\n",
    "   - LoRA/QLoRA for fine-tuning\n",
    "\n",
    "4. **How do you speed up inference?**\n",
    "   - KV caching\n",
    "   - Quantization (INT8, INT4)\n",
    "   - Flash Attention\n",
    "   - Batching\n",
    "\n",
    "---\n",
    "\n",
    "## Part 18: Code Snippets to Know\n",
    "\n",
    "### Basic Training Loop\n",
    "```python\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for x, y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "```\n",
    "\n",
    "### Inference Mode\n",
    "```python\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(inputs)\n",
    "    probabilities = F.softmax(predictions, dim=-1)\n",
    "```\n",
    "\n",
    "### DataLoader and Dataset\n",
    "```python\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.LongTensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = CustomDataset(X_train, y_train)\n",
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True  # faster GPU transfer\n",
    ")\n",
    "\n",
    "for batch_x, batch_y in dataloader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    batch_y = batch_y.to(device)\n",
    "    # training step...\n",
    "```\n",
    "\n",
    "### Custom Module\n",
    "```python\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(d_model, n_heads)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, 4*d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4*d_model, d_model)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.norm1(x), self.norm1(x), self.norm1(x))[0]\n",
    "        x = x + self.ffn(self.norm2(x))\n",
    "        return x\n",
    "```\n",
    "\n",
    "### Attention Implementation\n",
    "```python\n",
    "def attention(Q, K, V, mask=None):\n",
    "    d_k = Q.size(-1)\n",
    "    scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    return torch.matmul(weights, V)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Part 19: Quick Reference - Key Formulas\n",
    "\n",
    "### Machine Learning - Loss Functions\n",
    "- **MSE (Mean Squared Error):** $\\mathcal{L} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2$\n",
    "- **MAE (Mean Absolute Error):** $\\mathcal{L} = \\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y}_i|$\n",
    "- **Binary Cross-Entropy:** $\\mathcal{L} = -\\frac{1}{n}\\sum[y\\log(\\hat{y}) + (1-y)\\log(1-\\hat{y})]$\n",
    "- **Categorical Cross-Entropy:** $\\mathcal{L} = -\\sum_{c=1}^{C} y_c \\log(\\hat{y}_c)$\n",
    "- **Huber Loss:** $\\mathcal{L} = \\begin{cases} \\frac{1}{2}(y-\\hat{y})^2 & |y-\\hat{y}| \\leq \\delta \\\\ \\delta|y-\\hat{y}| - \\frac{1}{2}\\delta^2 & \\text{otherwise} \\end{cases}$\n",
    "- **KL Divergence:** $D_{KL}(P||Q) = \\sum P(x) \\log\\frac{P(x)}{Q(x)}$\n",
    "- **Contrastive Loss (InfoNCE):** $\\mathcal{L} = -\\log\\frac{\\exp(sim(z_i, z_j)/\\tau)}{\\sum_{k=1}^{2N}\\mathbb{1}_{k\\neq i}\\exp(sim(z_i, z_k)/\\tau)}$\n",
    "\n",
    "### Machine Learning - Activation Functions\n",
    "- **Sigmoid:** $\\sigma(x) = \\frac{1}{1 + e^{-x}}$, derivative: $\\sigma'(x) = \\sigma(x)(1-\\sigma(x))$\n",
    "- **Tanh:** $\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$, derivative: $\\tanh'(x) = 1 - \\tanh^2(x)$\n",
    "- **ReLU:** $f(x) = \\max(0, x)$, derivative: $f'(x) = \\begin{cases} 1 & x > 0 \\\\ 0 & x \\leq 0 \\end{cases}$\n",
    "- **Leaky ReLU:** $f(x) = \\max(\\alpha x, x)$ where $\\alpha \\approx 0.01$\n",
    "- **GeLU:** $f(x) = x \\cdot \\Phi(x) \\approx 0.5x(1 + \\tanh[\\sqrt{2/\\pi}(x + 0.044715x^3)])$\n",
    "- **Swish/SiLU:** $f(x) = x \\cdot \\sigma(x) = \\frac{x}{1 + e^{-x}}$\n",
    "- **Softmax:** $\\sigma(z)_i = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}$\n",
    "\n",
    "### Machine Learning - Regularization\n",
    "- **L1 (Lasso):** $\\mathcal{L}_{reg} = \\mathcal{L} + \\lambda\\sum|w_i|$\n",
    "- **L2 (Ridge):** $\\mathcal{L}_{reg} = \\mathcal{L} + \\lambda\\sum w_i^2$\n",
    "- **Elastic Net:** $\\mathcal{L}_{reg} = \\mathcal{L} + \\lambda_1\\sum|w_i| + \\lambda_2\\sum w_i^2$\n",
    "- **Dropout:** $\\tilde{y} = r \\odot y$ where $r \\sim \\text{Bernoulli}(p)$, scale by $1/(1-p)$ at train\n",
    "\n",
    "### Machine Learning - Metrics\n",
    "- **Accuracy:** $\\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "- **Precision:** $\\frac{TP}{TP + FP}$\n",
    "- **Recall (Sensitivity):** $\\frac{TP}{TP + FN}$\n",
    "- **F1 Score:** $2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}$\n",
    "- **Specificity:** $\\frac{TN}{TN + FP}$\n",
    "- **IoU (Jaccard):** $\\frac{|A \\cap B|}{|A \\cup B|}$\n",
    "- **R² Score:** $1 - \\frac{\\sum(y_i - \\hat{y}_i)^2}{\\sum(y_i - \\bar{y})^2}$\n",
    "\n",
    "### Machine Learning - Optimization\n",
    "- **SGD:** $\\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta \\mathcal{L}$\n",
    "- **SGD + Momentum:** $v_t = \\gamma v_{t-1} + \\eta \\nabla_\\theta \\mathcal{L}$, $\\theta_{t+1} = \\theta_t - v_t$\n",
    "- **Adam:** \n",
    "  - $m_t = \\beta_1 m_{t-1} + (1-\\beta_1)g_t$ (first moment)\n",
    "  - $v_t = \\beta_2 v_{t-1} + (1-\\beta_2)g_t^2$ (second moment)\n",
    "  - $\\hat{m}_t = m_t/(1-\\beta_1^t)$, $\\hat{v}_t = v_t/(1-\\beta_2^t)$ (bias correction)\n",
    "  - $\\theta_{t+1} = \\theta_t - \\eta \\hat{m}_t / (\\sqrt{\\hat{v}_t} + \\epsilon)$\n",
    "- **Learning Rate Decay:** $\\eta_t = \\eta_0 / (1 + \\text{decay} \\cdot t)$\n",
    "- **Cosine Annealing:** $\\eta_t = \\eta_{min} + \\frac{1}{2}(\\eta_{max} - \\eta_{min})(1 + \\cos(\\frac{t}{T}\\pi))$\n",
    "\n",
    "### Machine Learning - Statistics\n",
    "- **Bayes' Theorem:** $P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$\n",
    "- **Gaussian/Normal:** $p(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$\n",
    "- **Variance:** $\\text{Var}(X) = \\mathbb{E}[(X - \\mu)^2] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2$\n",
    "- **Covariance:** $\\text{Cov}(X,Y) = \\mathbb{E}[(X-\\mu_X)(Y-\\mu_Y)]$\n",
    "- **Entropy:** $H(X) = -\\sum p(x) \\log p(x)$\n",
    "\n",
    "---\n",
    "\n",
    "### Reinforcement Learning - Core\n",
    "- **Return:** $G_t = \\sum_{k=0}^{\\infty} \\gamma^k R_{t+k+1}$\n",
    "- **State Value:** $V^\\pi(s) = \\mathbb{E}_\\pi[G_t | S_t = s]$\n",
    "- **Action Value:** $Q^\\pi(s,a) = \\mathbb{E}_\\pi[G_t | S_t = s, A_t = a]$\n",
    "- **Advantage:** $A^\\pi(s,a) = Q^\\pi(s,a) - V^\\pi(s)$\n",
    "\n",
    "### Reinforcement Learning - Bellman Equations\n",
    "- **Bellman Expectation (V):** $V^\\pi(s) = \\sum_a \\pi(a|s) \\sum_{s'} P(s'|s,a)[R + \\gamma V^\\pi(s')]$\n",
    "- **Bellman Expectation (Q):** $Q^\\pi(s,a) = R(s,a) + \\gamma \\sum_{s'} P(s'|s,a) \\sum_{a'} \\pi(a'|s') Q^\\pi(s',a')$\n",
    "- **Bellman Optimality (V):** $V^*(s) = \\max_a \\sum_{s'} P(s'|s,a)[R + \\gamma V^*(s')]$\n",
    "- **Bellman Optimality (Q):** $Q^*(s,a) = R(s,a) + \\gamma \\sum_{s'} P(s'|s,a) \\max_{a'} Q^*(s',a')$\n",
    "\n",
    "### Reinforcement Learning - Algorithms\n",
    "- **Q-Learning:** $Q(s,a) \\leftarrow Q(s,a) + \\alpha[r + \\gamma \\max_{a'} Q(s',a') - Q(s,a)]$\n",
    "- **SARSA:** $Q(s,a) \\leftarrow Q(s,a) + \\alpha[r + \\gamma Q(s',a') - Q(s,a)]$\n",
    "- **TD(0):** $V(s) \\leftarrow V(s) + \\alpha[r + \\gamma V(s') - V(s)]$\n",
    "- **Policy Gradient:** $\\nabla_\\theta J(\\theta) = \\mathbb{E}_\\pi[\\nabla_\\theta \\log \\pi_\\theta(a|s) \\cdot Q^\\pi(s,a)]$\n",
    "- **REINFORCE:** $\\theta \\leftarrow \\theta + \\alpha \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t) \\cdot G_t$\n",
    "- **Actor-Critic:** $\\theta \\leftarrow \\theta + \\alpha \\nabla_\\theta \\log \\pi_\\theta(a|s) \\cdot \\delta_t$ where $\\delta_t = r + \\gamma V(s') - V(s)$\n",
    "- **PPO Clip:** $\\mathcal{L}^{CLIP} = \\mathbb{E}[\\min(r_t(\\theta)\\hat{A}_t, \\text{clip}(r_t(\\theta), 1-\\epsilon, 1+\\epsilon)\\hat{A}_t)]$\n",
    "- **DQN Loss:** $\\mathcal{L} = \\mathbb{E}[(r + \\gamma \\max_{a'} Q(s',a';\\theta^-) - Q(s,a;\\theta))^2]$\n",
    "- **SAC Entropy:** $J(\\pi) = \\sum_t \\mathbb{E}[r(s_t,a_t) + \\alpha H(\\pi(\\cdot|s_t))]$\n",
    "\n",
    "### Reinforcement Learning - Exploration\n",
    "- **ε-greedy:** $a = \\begin{cases} \\arg\\max_a Q(s,a) & \\text{prob } 1-\\epsilon \\\\ \\text{random} & \\text{prob } \\epsilon \\end{cases}$\n",
    "- **Boltzmann/Softmax:** $\\pi(a|s) = \\frac{e^{Q(s,a)/\\tau}}{\\sum_{a'} e^{Q(s,a')/\\tau}}$\n",
    "- **UCB:** $a = \\arg\\max_a [Q(s,a) + c\\sqrt{\\frac{\\ln t}{N(s,a)}}]$\n",
    "\n",
    "---\n",
    "\n",
    "### Deep Learning - Neural Networks\n",
    "- **Linear Layer:** $y = Wx + b$\n",
    "- **Batch Norm:** $\\hat{x} = \\frac{x - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}$, $y = \\gamma\\hat{x} + \\beta$\n",
    "- **Layer Norm:** $\\hat{x} = \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}$, $y = \\gamma\\hat{x} + \\beta$ (over features)\n",
    "- **RMS Norm:** $\\hat{x} = \\frac{x}{\\text{RMS}(x)}$, $\\text{RMS}(x) = \\sqrt{\\frac{1}{n}\\sum x_i^2}$\n",
    "- **Convolution:** $(f * g)(t) = \\sum_{\\tau} f(\\tau)g(t-\\tau)$\n",
    "- **Conv2D output size:** $\\text{out} = \\lfloor\\frac{\\text{in} + 2p - k}{s}\\rfloor + 1$\n",
    "\n",
    "### Deep Learning - Initialization\n",
    "- **Xavier/Glorot:** $W \\sim \\mathcal{U}(-\\sqrt{6/(n_{in}+n_{out})}, \\sqrt{6/(n_{in}+n_{out})})$\n",
    "- **He/Kaiming:** $W \\sim \\mathcal{N}(0, \\sqrt{2/n_{in}})$\n",
    "\n",
    "### Deep Learning - Gradient\n",
    "- **Chain Rule:** $\\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial x}$\n",
    "- **Gradient Clipping:** $g \\leftarrow g \\cdot \\min(1, \\frac{\\text{max\\_norm}}{||g||})$\n",
    "\n",
    "---\n",
    "\n",
    "### Transformers - Attention\n",
    "- **Scaled Dot-Product:** $\\text{Attention}(Q,K,V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$\n",
    "- **Multi-Head:** $\\text{MultiHead}(Q,K,V) = \\text{Concat}(\\text{head}_1,...,\\text{head}_h)W^O$\n",
    "- **Each head:** $\\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)$\n",
    "- **Causal Mask:** $M_{ij} = \\begin{cases} 0 & i \\geq j \\\\ -\\infty & i < j \\end{cases}$\n",
    "\n",
    "### Transformers - Position Encoding\n",
    "- **Sinusoidal:** $PE_{(pos,2i)} = \\sin(pos/10000^{2i/d})$, $PE_{(pos,2i+1)} = \\cos(pos/10000^{2i/d})$\n",
    "- **RoPE:** $q_m = R_{\\Theta,m}W_q x_m$ where $R_{\\Theta,m}$ is rotation matrix\n",
    "\n",
    "### Transformers - Architecture\n",
    "- **FFN:** $\\text{FFN}(x) = \\text{ReLU}(xW_1 + b_1)W_2 + b_2$\n",
    "- **SwiGLU:** $\\text{SwiGLU}(x) = \\text{Swish}(xW_1) \\odot (xW_3)$\n",
    "- **Pre-Norm Block:** $x = x + \\text{Attention}(\\text{LN}(x))$, $x = x + \\text{FFN}(\\text{LN}(x))$\n",
    "- **Post-Norm Block:** $x = \\text{LN}(x + \\text{Attention}(x))$, $x = \\text{LN}(x + \\text{FFN}(x))$\n",
    "\n",
    "### Transformers - Complexity\n",
    "- **Self-Attention:** $O(n^2 \\cdot d)$ time, $O(n^2)$ memory\n",
    "- **FFN:** $O(n \\cdot d^2)$ time\n",
    "- **Sliding Window:** $O(n \\cdot w \\cdot d)$ where $w$ = window size\n",
    "\n",
    "---\n",
    "\n",
    "### Robotics - Kinematics\n",
    "- **Forward Kinematics:** $x = f(q)$ (joint angles → end-effector pose)\n",
    "- **Inverse Kinematics:** $q = f^{-1}(x)$ (end-effector pose → joint angles)\n",
    "- **Jacobian:** $\\dot{x} = J(q)\\dot{q}$\n",
    "- **Jacobian Inverse:** $\\dot{q} = J^{-1}(q)\\dot{x}$ or $\\dot{q} = J^+(q)\\dot{x}$ (pseudo-inverse)\n",
    "- **Singularity:** $\\det(J) = 0$ (robot loses DOF)\n",
    "\n",
    "### Robotics - Dynamics\n",
    "- **Equation of Motion:** $M(q)\\ddot{q} + C(q,\\dot{q})\\dot{q} + G(q) = \\tau$\n",
    "  - $M$: mass matrix, $C$: Coriolis, $G$: gravity, $\\tau$: torques\n",
    "- **Impedance Control:** $F = M_d\\ddot{x} + B_d\\dot{x} + K_d(x - x_d)$\n",
    "\n",
    "### Robotics - Control\n",
    "- **PID:** $u(t) = K_p e(t) + K_i \\int_0^t e(\\tau)d\\tau + K_d \\frac{de(t)}{dt}$\n",
    "- **PD + Gravity Comp:** $\\tau = K_p(q_d - q) + K_d(\\dot{q}_d - \\dot{q}) + G(q)$\n",
    "- **Computed Torque:** $\\tau = M(q)(\\ddot{q}_d + K_d\\dot{e} + K_p e) + C(q,\\dot{q})\\dot{q} + G(q)$\n",
    "\n",
    "### Robotics - Transformations\n",
    "- **Homogeneous Transform:** $T = \\begin{bmatrix} R & t \\\\ 0 & 1 \\end{bmatrix}$ (4×4)\n",
    "- **Rotation Matrix (z-axis):** $R_z(\\theta) = \\begin{bmatrix} \\cos\\theta & -\\sin\\theta & 0 \\\\ \\sin\\theta & \\cos\\theta & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$\n",
    "- **Quaternion:** $q = w + xi + yj + zk$, $||q|| = 1$ for rotation\n",
    "- **Quaternion to Rotation:** $R = I + 2w[\\mathbf{v}]_\\times + 2[\\mathbf{v}]_\\times^2$ where $\\mathbf{v} = (x,y,z)$\n",
    "\n",
    "### Robotics - Planning\n",
    "- **A* Heuristic:** $f(n) = g(n) + h(n)$ (cost-so-far + estimated-to-goal)\n",
    "- **RRT Steering:** $q_{new} = q_{near} + \\frac{q_{rand} - q_{near}}{||q_{rand} - q_{near}||} \\cdot \\delta$\n",
    "- **MPC Cost:** $J = \\sum_{t=0}^{H}[x_t^T Q x_t + u_t^T R u_t]$ subject to $x_{t+1} = f(x_t, u_t)$\n",
    "\n",
    "### Robotics - Balance (Humanoids)\n",
    "- **ZMP (Zero Moment Point):** Point where horizontal moments = 0\n",
    "- **CoM Dynamics:** $\\ddot{x}_{CoM} = \\frac{g}{z_{CoM}}(x_{CoM} - x_{ZMP})$ (linear inverted pendulum)\n",
    "- **Stability:** ZMP must stay within support polygon\n",
    "\n",
    "---\n",
    "\n",
    "### Diffusion Models\n",
    "- **Forward Process:** $q(x_t|x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1-\\beta_t}x_{t-1}, \\beta_t I)$\n",
    "- **Reverse Process:** $p_\\theta(x_{t-1}|x_t) = \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t, t), \\Sigma_\\theta(x_t, t))$\n",
    "- **Training Loss:** $\\mathcal{L} = \\mathbb{E}_{t,x_0,\\epsilon}[||\\epsilon - \\epsilon_\\theta(x_t, t)||^2]$\n",
    "- **Sampling:** $x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}}(x_t - \\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\epsilon_\\theta(x_t,t)) + \\sigma_t z$\n",
    "\n",
    "### Flow Matching\n",
    "- **Velocity Field:** $\\frac{dx_t}{dt} = v_\\theta(x_t, t)$\n",
    "- **Training Loss:** $\\mathcal{L} = \\mathbb{E}_{t,x_0,x_1}[||v_\\theta(x_t, t) - (x_1 - x_0)||^2]$\n",
    "- **Sampling:** $x_1 = x_0 + \\int_0^1 v_\\theta(x_t, t) dt$ (ODE solver)\n",
    "\n",
    "---\n",
    "\n",
    "### Information Theory\n",
    "- **Entropy:** $H(X) = -\\sum_x p(x) \\log p(x)$\n",
    "- **Cross-Entropy:** $H(p,q) = -\\sum_x p(x) \\log q(x)$\n",
    "- **KL Divergence:** $D_{KL}(p||q) = \\sum_x p(x) \\log \\frac{p(x)}{q(x)} = H(p,q) - H(p)$\n",
    "- **Mutual Information:** $I(X;Y) = H(X) - H(X|Y) = H(X) + H(Y) - H(X,Y)$\n",
    "\n",
    "### Linear Algebra Essentials\n",
    "- **Matrix Inverse:** $AA^{-1} = I$\n",
    "- **Pseudo-inverse:** $A^+ = (A^T A)^{-1} A^T$ (left), $A^+ = A^T(AA^T)^{-1}$ (right)\n",
    "- **SVD:** $A = U\\Sigma V^T$\n",
    "- **Eigendecomposition:** $Av = \\lambda v$\n",
    "- **Determinant:** $\\det(AB) = \\det(A)\\det(B)$\n",
    "- **Trace:** $\\text{tr}(ABC) = \\text{tr}(CAB) = \\text{tr}(BCA)$\n",
    "\n",
    "---\n",
    "\n",
    "## Part 20: Additional Interview Tips\n",
    "\n",
    "### 20.1 Coding Interview Tips\n",
    "\n",
    "1. **Start simple:** Implement baseline first, then optimize\n",
    "2. **Think aloud:** Explain your reasoning\n",
    "3. **Test your code:** Walk through with examples\n",
    "4. **Handle edge cases:** Empty inputs, single elements\n",
    "5. **Know complexity:** Time and space analysis\n",
    "\n",
    "### 20.2 ML Interview Tips\n",
    "\n",
    "1. **Know your resume:** Be ready to deep-dive on any project\n",
    "2. **Understand tradeoffs:** No solution is perfect\n",
    "3. **Ask clarifying questions:** Requirements, constraints, scale\n",
    "4. **Start with baselines:** Simple models first\n",
    "5. **Discuss failure modes:** What could go wrong?\n",
    "\n",
    "### 20.3 Common Behavioral Questions\n",
    "\n",
    "1. **Tell me about a challenging ML project**\n",
    "   - Problem → Approach → Challenges → Results → Learnings\n",
    "\n",
    "2. **How do you handle disagreements with teammates?**\n",
    "   - Listen → Understand → Data-driven discussion → Compromise\n",
    "\n",
    "3. **Describe a time you failed**\n",
    "   - Situation → What went wrong → What you learned → How you improved\n",
    "\n",
    "4. **How do you stay current with ML research?**\n",
    "   - Papers (arXiv), conferences, blogs, implementations\n",
    "\n",
    "### 20.4 Questions to Ask Interviewers\n",
    "\n",
    "- What does the ML infrastructure look like?\n",
    "- How do you handle model deployment and monitoring?\n",
    "- What's the team structure and collaboration like?\n",
    "- What are the biggest technical challenges?\n",
    "- How do you balance research vs production?\n",
    "\n",
    "---\n",
    "\n",
    "*End of Interview Preparation Guide*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dad429",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
